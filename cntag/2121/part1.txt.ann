概述篇 1 概述篇 1.1 [@机器学习#ai_tec*]的概念 [$机器学习#ai_tec*]已经成为了当今的热门话题，但是从[$机器学习#ai_tec*]这个概念诞生到[$机器学习#ai_tec*]技术的普遍应用经过了漫长的过程。在[$机器学习#ai_tec*]发展的历史长河中，众多优秀的学者为推动[$机器学习#ai_tec*]的发展做出了巨大的贡献。 从[@1642#Date*] 年 [@Pascal #Person*]发明的[@手摇式计算机#MISC*]，到[@1949#Date*] 年 [@Donald Hebb #Person*]提出的赫布理论——解释学习过程中大脑神经元所发生的变化，都蕴含着[$机器学习#ai_tec*]思想的萌芽。事实上，[@1950 #Date*]年[@图灵#Date*]在关于[$图灵#Date*]测试的文章中就已提及[$机器学习#ai_tec*]的概念。到了[@1952 #Date*]年，[@IBM#Org*]的[@亚瑟·塞缪尔#Person*]（[@Arthur Samuel#Person*]，被誉为“[$机器学习#ai_tec*]之父”）设计了一款可以学习的[@西洋跳棋程序#ai_product*]。[@塞缪尔#Person*]和这个程序进行多场对弈后发现，随着时间的推移，程序的棋艺变得越来越好[1]。[$塞缪尔#Person*]用这个程序推翻了以往“机器无法超越人类，不能像人一样写代码和学习”这一传统认识。并在 [@1956#Date*] 年正式提出了“[$机器学习#ai_tec*]”这一概念。 对[$机器学习#ai_tec*]的认识可以从多个方面进行，有着“全球[$机器学习#ai_tec*]教父”之称的[@Tom Mitchell#Person*] 则将[$机器学习#ai_tec*]定义为：对于某类任务T 和性能度量 P，如果计算机程序在 T 上以P衡量的性能随着经验 E 而自我完善，就称这个计算机程序从经验 E 学习。 普遍认为，[$机器学习#ai_tec*]（[@Machine Learning#ai_tec*]，常简称为[@ML#ai_tec*]）的处理系统和算法是主要通过找出数据里隐藏的模式进而做出预测的识别模式，它是[@人工智能#ai_tec*]（[@Artificial Intelligence#ai_tec*]，常简称为[@AI#ai_tec*]）的一个重要子领域。 1.2 [$机器学习#ai_tec*]的发展历史 从[$机器学习#ai_tec*]发展的过程上来说，其发展的时间轴如下所示：图1-1 [$机器学习#ai_tec*]发展历程 1 [@深度学习#ai_tec*]篇 3 [$深度学习#ai_tec*]篇 [$深度学习#ai_tec*]是近 10 年[$机器学习#ai_tec*]领域发展最快的一个分支，由于其重要性，三位教授（[@Geoffrey Hinton#Person*]、[@Yann Lecun#Person*]、[@Yoshua Bengio#Person*]）因此同获[$图灵#Date*]奖。[$深度学习#ai_tec*]模型的发展可以追溯到[@1958 #Date*]年的感知机（Perceptron）。[@1943#Date*]年[@神经网络#ai_tec*]就已经出现雏形（源自NeuroScience），[$1958 #Date*]年研究认知的心理学家[@Frank#Person*] 发明了感知机，当时掀起一股热潮。后来[@Marvin Minsky#Person*]（[$人工智能#ai_tec*]大师）和[@Seymour Papert #Person*]发现感知机的缺陷：不能处理异或回路等非线性问题，以及当时存在计算能力不足以处理大型[$神经网络#ai_tec*]的问题。于是整个[$神经网络#ai_tec*]的研究进入停滞期。 最近30 年来取得快速发展。总体来说，主要有4 条发展脉络： 图 3-1 [$深度学习#ai_tec*]模型最近若干年的重要进展 以下各小节是对[$深度学习#ai_tec*]不同方面发展情况的梳理： 11 [$人工智能#ai_tec*]之[$机器学习#ai_tec*] 项关于图[$深度学习#ai_tec*]的最新调查，却忽略了对图生成网络和图时空网络的研究。总之，现有的研究没有一个对图[$神经网络#ai_tec*]进行全面的回顾，只覆盖了部分图卷积[$神经网络#ai_tec*]且检查的研究有限，因此遗漏了图[$神经网络#ai_tec*]替代方法的最新进展，如图生成网络和图时空网络[17]。 3.9[$深度学习#ai_tec*]近期重要进展 在过去几年中，[$深度学习#ai_tec*]改变了整个[$人工智能#ai_tec*]的发展。[$深度学习#ai_tec*]技术已经开始在医疗保健，金融，人力资源，零售，地震检测和[@自动驾驶汽车#ai_tec*]等领域的应用程序中出现。至于现有的成果表现也一直在稳步提高。本小节将介绍[$深度学习#ai_tec*]近期的一些重要进展。 3.9.1 [@2018#Date*] 年三大进展 ? [@BERT#ai_tec*]模型 [$BERT#ai_tec*]的全称是Bidirectional Encoder Representation from Transformers，是基于[@深度双向Transformer#ai_tec*] 的预训练模型，能用所有层的上下文语境训练深度双向表征。自 [@Google #Org*]在 [$2018#Date*]年公布[$BERT#ai_tec*] 在 11 项 [@nlp#ai_tec*] 任务中的卓越表现后，[$BERT#ai_tec*]就成为 [@NLP#ai_tec*]领域大火的模型。关于[$BERT#ai_tec*]的详细介绍请参见2.9 节的内容。 ? 视频到视频合成（Video-to-Video Synthesis） 我们通常习惯由图形引擎创建的模拟器和视频游戏进行环境交互。虽然令人印象深刻，但经典方法的成本很高，因为必须精心指定场景几何、材料、照明和其他参数。一个很好的问题是：是否可以使用例如[$深度学习#ai_tec*]技术自动构建这些环境。[@NVIDIA#Org*] 的研究人员解决了这个问题。他们的目标是在源视频和输出视频之间提供映射功能，精确描绘输入内容。作者将其建模为分布匹配问题，其目标是使自动创建视频的条件分布尽可能接近实际视频的条件分布。为实现这一目标，他们建立了一个基于[@生成对抗网络#MISC*]（[@GAN#MISC*]）的模型。在[$GAN#MISC*] 框架内的关键思想是，生成器试图产生真实的合成数据，使得鉴别器无法区分真实数据和合成数据。他们定义了一个时空学习目标，旨在实现暂时连贯的视频[18]。 ? 图网络（Graph Network） DeepMind 联合[@谷歌大脑#Org*]、[@MIT#Org*]等机构27 位作者发表重磅论文“Relational inductive biases, deep learning, and graph networks”，提出“图网络”（Graph network），将端到端学习与归纳推理相结合，有望解决[$深度学习#ai_tec*]无法进行关系推理的问题。作者认为组合泛化是[$人工智能#ai_tec*]实现与人类相似能力的首要任务，而结构化表示和计算是实现这一目标的关键，实现这个目标的关键是结构化的表示数据和计算。该论文讨论了图网络如何支持关系推理和组合泛化，为更复杂的、可解释的和灵活的推理模式奠定基础[19]。 16 [$深度学习#ai_tec*]篇 3.9.2 2019 年三大进展 ? [@XLNet #ai_tec*]模型 [$XLNet #ai_tec*]是[@CMU#Org*]与[$谷歌大脑#Org*]提出的全新[$NLP#ai_tec*] 模型，在 20 个任务上超过了 [$BERT#ai_tec*] 的表现，并在 18 个任务上取得了当前最佳效果，包括[@机器问答#ai_product*]、[@自然语言推断#ai_product*]、[@情感分析#ai_product*]和文档排序。关于[$XLNet #ai_tec*]及其与[$BERT#ai_tec*] 关系的详细介绍请参见2.9 节的内容。 ? MoCo [@何恺明#Person*]在其工作“Momentum Contrast for Unsupervised Visual Representation L