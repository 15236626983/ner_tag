概述篇 1 概述篇 1.1 机器学习的概念 机器学习已经成为了当今的热门话题，但是从机器学习这个概念诞生到机器学习技术的普遍应用经过了漫长的过程。在机器学习发展的历史长河中，众多优秀的学者为推动机器学习的发展做出了巨大的贡献。 从1642 年 Pascal 发明的手摇式计算机，到1949 年 Donald Hebb 提出的赫布理论——解释学习过程中大脑神经元所发生的变化，都蕴含着机器学习思想的萌芽。事实上，1950 年图灵在关于图灵测试的文章中就已提及机器学习的概念。到了1952 年，IBM的亚瑟·塞缪尔（Arthur Samuel，被誉为“机器学习之父”）设计了一款可以学习的西洋跳棋程序。塞缪尔和这个程序进行多场对弈后发现，随着时间的推移，程序的棋艺变得越来越好[1]。塞缪尔用这个程序推翻了以往“机器无法超越人类，不能像人一样写代码和学习”这一传统认识。并在 1956 年正式提出了“机器学习”这一概念。 对机器学习的认识可以从多个方面进行，有着“全球机器学习教父”之称的Tom Mitchell 则将机器学习定义为：对于某类任务T 和性能度量 P，如果计算机程序在 T 上以P衡量的性能随着经验 E 而自我完善，就称这个计算机程序从经验 E 学习。 普遍认为，机器学习（Machine Learning，常简称为ML）的处理系统和算法是主要通过找出数据里隐藏的模式进而做出预测的识别模式，它是人工智能（Artificial Intelligence，常简称为AI）的一个重要子领域。 1.2 机器学习的发展历史 从机器学习发展的过程上来说，其发展的时间轴如下所示：图1-1 机器学习发展历程 1 深度学习篇 3 深度学习篇 深度学习是近 10 年机器学习领域发展最快的一个分支，由于其重要性，三位教授（Geoffrey Hinton、Yann Lecun、Yoshua Bengio）因此同获图灵奖。深度学习模型的发展可以追溯到1958 年的感知机（Perceptron）。1943年神经网络就已经出现雏形（源自NeuroScience），1958 年研究认知的心理学家Frank 发明了感知机，当时掀起一股热潮。后来Marvin Minsky（人工智能大师）和Seymour Papert 发现感知机的缺陷：不能处理异或回路等非线性问题，以及当时存在计算能力不足以处理大型神经网络的问题。于是整个神经网络的研究进入停滞期。 最近30 年来取得快速发展。总体来说，主要有4 条发展脉络： 图 3-1 深度学习模型最近若干年的重要进展 以下各小节是对深度学习不同方面发展情况的梳理： 11 人工智能之机器学习 项关于图深度学习的最新调查，却忽略了对图生成网络和图时空网络的研究。总之，现有的研究没有一个对图神经网络进行全面的回顾，只覆盖了部分图卷积神经网络且检查的研究有限，因此遗漏了图神经网络替代方法的最新进展，如图生成网络和图时空网络[17]。 3.9深度学习近期重要进展 在过去几年中，深度学习改变了整个人工智能的发展。深度学习技术已经开始在医疗保健，金融，人力资源，零售，地震检测和自动驾驶汽车等领域的应用程序中出现。至于现有的成果表现也一直在稳步提高。本小节将介绍深度学习近期的一些重要进展。 3.9.1 2018 年三大进展 ? BERT模型 BERT的全称是Bidirectional Encoder Representation from Transformers，是基于深度双向Transformer 的预训练模型，能用所有层的上下文语境训练深度双向表征。自 Google 在 2018年公布BERT 在 11 项 nlp 任务中的卓越表现后，BERT就成为 NLP领域大火的模型。关于BERT的详细介绍请参见2.9 节的内容。 ? 视频到视频合成（Video-to-Video Synthesis） 我们通常习惯由图形引擎创建的模拟器和视频游戏进行环境交互。虽然令人印象深刻，但经典方法的成本很高，因为必须精心指定场景几何、材料、照明和其他参数。一个很好的问题是：是否可以使用例如深度学习技术自动构建这些环境。NVIDIA 的研究人员解决了这个问题。他们的目标是在源视频和输出视频之间提供映射功能，精确描绘输入内容。作者将其建模为分布匹配问题，其目标是使自动创建视频的条件分布尽可能接近实际视频的条件分布。为实现这一目标，他们建立了一个基于生成对抗网络（GAN）的模型。在GAN 框架内的关键思想是，生成器试图产生真实的合成数据，使得鉴别器无法区分真实数据和合成数据。他们定义了一个时空学习目标，旨在实现暂时连贯的视频[18]。 ? 图网络（Graph Network） DeepMind 联合谷歌大脑、MIT等机构27 位作者发表重磅论文“Relational inductive biases, deep learning, and graph networks”，提出“图网络”（Graph network），将端到端学习与归纳推理相结合，有望解决深度学习无法进行关系推理的问题。作者认为组合泛化是人工智能实现与人类相似能力的首要任务，而结构化表示和计算是实现这一目标的关键，实现这个目标的关键是结构化的表示数据和计算。该论文讨论了图网络如何支持关系推理和组合泛化，为更复杂的、可解释的和灵活的推理模式奠定基础[19]。 16 深度学习篇 3.9.2 2019 年三大进展 ? XLNet 模型 XLNet 是CMU与谷歌大脑提出的全新NLP 模型，在 20 个任务上超过了 BERT 的表现，并在 18 个任务上取得了当前最佳效果，包括机器问答、自然语言推断、情感分析和文档排序。关于XLNet 及其与BERT 关系的详细介绍请参见2.9 节的内容。 ? MoCo 何恺明在其工作“Momentum Contrast for Unsupervised Visual Representation L