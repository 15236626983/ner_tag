CIKM、COLING等学术会议上发表相关专业论文并担任 2000年 ACL北美分会执行委员会成员、 2010年-2015年[@美国#Gep*]国家标准与Ralph Grishman的高引用论文“ A maximum entropy approach to named entity recognition”识别是一种信息提取形式，将文档中的每个单词分类为人名、组织、位置、日期、时间、货。对互联网搜索引擎、[@机器翻译#ai_tec*]、文档的自动索引以及作周国栋周国栋，苏州大学计算机科学与技术学院特聘教授，苏州大学自然语言处理实验室创建人，中国[@人工智能#ai_tec*]学会自然语言理解专委会和 CCF中文信息技术专委会副主任委员。周国栋的研究涵盖[@自然语言处理#ai_tec*]、[@知识获取#ai_tec*]、[@信息抽取#ai_tec*]、[@隐马尔科夫模型#ai_tec*]研究等方向，主持完成多项国家级科研项目，曾任国际顶级期刊《 Computational Linguistics》杂志编委， NSFC信息学部会评专家以及许多著名的国际杂志和会议的评审和委员会委员。近年来在 ACL、COLING、IJCAI等国际顶级会议发表相关专业论文超过 80篇，并获得 IEEE会士、 ACM会士、 ACL会士等多项荣誉。周国栋高引用论文是 2002年在 ACL上发表的“ Named entity recognition using an HMM-based chunk tagger”提出了一种[$隐马尔科夫模型#ai_tec*]和一种基于该模型的[@模块标记器#ai_product*]，从中建立了一个命名实体识别系统用于识别并分类名称、时间与数量。通过这一模型系统能够应用和整合四种类型的内部和外部证据，从而有效地解决 NER问题，基于该系统对 MUC-6和 MUC-7英语 NE任务的系统评估分别达到 96.6％和 94.1％，性能明显优于任何其他[@机器学习#ai_tec*]系统。[@黄萱菁#Person*][$黄萱菁#Person*]，复旦大学计算机科学技术学院教授，中国中文信息学会理事，《中文信息学报》编委，中国计算机学会中文信息技术专委会委员，中国[$人工智能#ai_tec*]学会自然语言理解专业委员会委员。[$黄萱菁#Person*]的研究涵盖[@问答系统#ai_tec*]、[$自然语言处理#ai_tec*]、中文信息编译等方向， 2005年至 2010年间有多项研究成果产出，曾多次在[$人工智能#ai_tec*]、[$自然语言处理#ai_tec*]和信息检索的国际学术会议 IJCAI、ACL、SIGIR、WWW、EMNLP、COLING、CIKM、WSDM担任程序委员会委员、资深委员、竞赛主席等职务。在 SIGIR、ACL、ICML、IJCAI、AAAI、NIPS、CIKM、ISWC、 EMNLP、WSDM和 COLING等多个国际学术会议上发表论文数十篇的同时收获 ACM会士、ACL会士等多项荣誉。[$黄萱菁#Person*]的高引用论文是 [@2009年#Date*]在 EMNLP上发表的“ Phrase dependency parsing for opinion mining”提出了一种从产品评论中挖掘挖掘意见的新方法，这种方法将意见挖掘任务转换为识别产品特征、意见表达和它们之间关系，通过多种产品的特征是基于短语所观察的特点引入了短语依赖性解析的概念，将传统的依赖性解析扩展到短语级别，然后实现了该概念以提取产品特征和意见表达之间的关系，经过实验评估表明挖掘任务可以受益于该种方法的短语依赖性解析。 2.3.[@知识融合#ai_tec*][@知识图谱#ai_tec*]可以由任何机构和个人自由构建，其背后的数据来源广泛、质量参差不齐，导致它们之间存在多样性和异构性。语义集成的提出就是为了能够将不同的[$知识图谱#ai_tec*]融合为一个统一、一致、简洁的形式，为使用不同[$知识图谱#ai_tec*]的应用程序间的交互建立操作性。常用的技术包括[@本体匹配#ai_tec*]（也称为本体映射）、[@实力匹配#ai_tec*]（也称为实体对齐、对象公指消解）以及[$知识融合#ai_tec*]等。图 15[@语义集成#ai_tec*]的常见流程一个[$语义集成#ai_tec*]的常见流程，主要包括：输入、预处理、匹配、[$知识融合#ai_tec*]和输出 5个环节。[$语义集成#ai_tec*]的输入包括待集成的若干个知识库以及配置、外部资源等，如图 15所示。待集成的知识库格式一般为 RDF/OWL数据文件或 SPARQL端点（endpoint）。外部资源是[$语义集成#ai_tec*]过程中使用到的背景知识，例如字/辞典背景知识（例如 WordNet）、常识背景知识（例如 Cyc）、实时背景知识（例如搜索引擎）等。预处理主要包括对输入知识库进行清洗和后续步骤的准备。清洗主要是为了解决输入质量问题，与自有文本不同，知识库通常基于 RDF/OWL语言构建，质量较好。后续步骤的准备分为配置和数据两方面。根据匹配对象的不同，匹配一般分为[$本体匹配#ai_tec*]和[$实力匹配#ai_tec*]两方面。文本相似性度是发现匹配的最基础方法，大致可分为四种类型：基于字符的（例如 Leven-shtein编辑距离）、基于单词的（例如 Jaccard系数）、混合型（例如 soft TF-IDF）和基于语义的（例如 WordNet）。在匹配的基础上，[$知识融合#ai_tec*]一般通过冲突检测、真值发现等技术消解知识集成过程中的冲突，再对知识进行关联与合并，最终形成一个一致的结果。语义集的输出是一个统一的、一致的、简洁的知识库。 2.3.1.[$本体匹配#ai_tec*]伴随链接数据的蓬勃发展，本体的数量越来越多。现有大多数[$本体匹配#ai_tec*]方法处理的是成对的本体，但是成对匹配方法在同时匹配多个本体时会产生一些问题，最主要的问题是它们得到的结果从全局看可能存在冲突。 [@LPHIM#ai_tec*]是一种多文本全体匹配方法，能够在匹配多个本体的同时保证结果是全局最优解。随着多语言知识库的发展，跨语言[$本体匹配#ai_tec*]方法的重要性已经凸显。由于语言不同，跨语言[$本体匹配#ai_tec*]相较一般[$本体匹配#ai_tec*]更为困难，特别是影响文本相似性度量的准确性。较有代表性的工作包括： [@EAFG#ai_tec*]和[@双语主题模型#ai_tec*]。 2.3.2.实例匹配众包和主动学习等人机协作方法是目前实例匹配的研究热点。这些方法雇佣普通用户，随着表示学习技术在诸如图像、视频、语言、[$自然语言处理#ai_tec*]等领域的成功，一些研究人员开始着手研究面向[$知识图谱#ai_tec*]的表示学习技术，将实体、关系等转换成一个低维空间中的实并在[$知识图谱#ai_tec*]补全、知识库问答等应用中取得了不错的效果。近年来，强化学习取得了一些列进展，如何在[$语义集成#ai_tec*]中运用强化学习逐渐成为新的动向。[@ALEX#ai_product*]是一个通过利用用户提供的查询答案反馈来提高实例匹配质量的系统，它将每个匹配视作一个状态，用户反馈被转换为行为奖励，通过最大化收集到的行为奖励改善策略。 2.3.3.[$知识融合#ai_tec*]人才介绍选取 knowledge integration、knowledge linking、knowledge fusion、semantic integration heterogeneous knowledge、ontology matching、ontology alignment、linked data、linked-data、 linked open data，instance matching，instance mapping，ontology mapping，entity matching， schema matching等词作为[$知识融合#ai_tec*]领域关键词，按照图 2所示流程将所选学者定义为该领域知名学者并对其进行统计分析，最终绘制出该领域全球知名学者分布图，分别如图 16、图 17所示：图 16[$知识融合#ai_tec*]领域全球知名学者分布图及北美洲，亚洲次之，大洋洲、南美洲等较为匮乏。若按国家进行统计，[$美国#Gep*]是该领域学者最为集中的国家，境内学者数量多集中分布在东海岸，德国、中国、英国等国家学者数量次之，其他国家人数较少。对符合上述条件的我国[$知识融合#ai_tec*]领域学者分布进行分析，绘制中国范围内[$知识融合#ai_tec*]领域知名学者分布图，如图 18所示：图 18[$知识融合#ai_tec*]领域中国知名学者分布图中国[$知识融合#ai_tec*]领域知名学者人数较少，其中多数学者集中分布在环渤海经济圈以及华东地区，地域性明显。对[$知识融合#ai_tec*]领域知名学者进行计算分析，最终绘制出该领域各国人才迁徙图，整体情况图 19所示：图 19[$知识融合#ai_tec*]领域各国知名学者迁徙图Renée J. Miller Renée J. Miller，NSERC商业智能战略网络领导人。多伦多大学计算机科学教授，[$美国#Gep*]Renée J. Miller自 2000年涉足[$知识图谱#ai_tec*]及相关领域，研究涵盖数据交换、[$知识融合#ai_tec*]、数据集成、知识管理和数据共享等方向，曾任 2011年 ACM SIGMOD计划主席，在数据整合及完整性领域建树颇多，并因此荣获总统青年研究员奖、 2003年 ICDT时间测试奖、 ACMRenée J. Miller的代表性论文是 2003年在 ICDT上发表的“ Data Exchange: Semantics and Query Answering”给出了一个代数规范，这种规范代表了可能解决方案的整个空间从而使其在数据交换问题的所有解决方案中能够选择通用的特殊解决方案作为问题的解决方法。论文研究了在这种情况下计算某些答案的计算复杂性，并通过在规范的通用解决方案上评估它们来研究计算目标查询的某些答案，分析并解决了数据交换语义相关的基础算法以及在数据交换环境中查询答案的问题，被学术界认可为数据交换的奠基性文章。 Felix Naumann Felix Naumann，是哈索 ·普拉特钠数字工程研究院（ Hasso-Plattner-Institut für Digital Engineering gGmbH,HPI）的教授。隶属于公立波茨坦大学的 HPI，是 IT领域的德国大学卓越中心。 [@Felix Naumann#Person*]是数字工程系主任，信息系统教授，德国计算机科学协会数据库部分发言人。 [$Felix Naumann#Person*]的高引用论文是 2005年在 ICDE上发表的“ Schema Matching Using Duplicates”展示了利用数据集中重复项的存在来自动识别匹配的属性，论文中介绍的算法能够通过比较重复记录中的数据识别相应的属性，经过验证已经证实了该方法的有效性。 [$Felix Naumann#Person*]的研究涵盖[@数据挖掘#ai_tec*]、[@数据完整性#ai_tec*]、[$知识融合#ai_tec*]等方向， 2005年前后研究成果增长迅速。曾任 QCRI访问首席科学家、 [@2012年#Date*] EDBT演示主席、 2017年 VLDB行业联合主席、 2018年 VLDB副主编等职务。多次受邀出席国际顶级学术会议，指导学生获得 2014年 PROFILES和 KnowLODFelix Roberto Navigli Roberto Navigli是罗马大学计算机科学系的教授，语言计算实验室的成员，他是 ELEXIS Sapienza部门的协调员， CINI[$人工智能#ai_tec*]和智能系统国家实验室的指导委员会成员，同时是欧洲为数不多的获得欧洲研究理事会（ ERC）两项奖学金的研究人员之一。 Roberto Navigli是BabelNet的创始人， BabelNet是最大的高质量多语言百科全书计算机辞典。他 2013年在ACM上发表的论文的高引论文“ BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network”，提出了构建 BabelNet的自动方法，一个覆盖广泛的大型多语言语义网络。该网络通过从WordNet和维基百科中整合词典性与百科式知识，自动构建资源。此外，[$机器翻译#ai_tec*]也被用于丰富所有语言的词汇信息资源。我们在新的和现有的标准数据集上进行的实验证明了这一资源的高品质与覆盖范围。苏俭苏俭，大规模技术部署首席专家、 BIRC[$自然语言处理#ai_tec*]部门主管、联合主任， SIGDAT总裁及顾问委员会成员， 2018-2020年 ACL亚太分会创始执行董事会成员。苏俭的研究涵盖[$机器学习#ai_tec*]、[@信息提取#ai_tec*]、[@情感分析#ai_tec*]，[@文本挖掘#ai_tec*]、[$机器翻译#ai_tec*]、[$自然语言处理#ai_tec*]等方向，[$2012年#Date*]前后开始专注研究生物信息。曾任 ACL等国际会议、期刊编委会成员， 2015-2016年 EMNLP项目主席。 2010年、2011年、[$2012年#Date*]分别在 COLING、IJCAI发表 3篇文章，除此之外，她还获得 2000年 CONLL最佳个人系统奖、 2004年 CONLING最佳表现奖等奖项。苏俭 2002年发表在 ACL上的高引用论文 “Named entity recognition using an HMM-based chunk tagger”提出了一种[$隐马尔科夫模型#ai_tec*]和一种基于该模型的标记器，系统基于上述模型能够有效解决 NER问题，且性能明显优于任何其他[$机器学习#ai_tec*]系统。Jér.me Euzenat 2.4.[$知识图谱#ai_tec*]查询和推理计算 2.4.1.知识推理知识推理从给定的[$知识图谱#ai_tec*]推导出新的实体跟实体之间的关系。[$知识图谱#ai_tec*]推理可以分为基于符号的推理和基于统计的推理。在[$人工智能#ai_tec*]的研究中，基于符号的推理一般是基于经典逻辑（一阶谓词逻辑或者命题逻辑）或者经典逻辑的变异（比如说缺省逻辑）。基于符号的推理可以从一个已有的[$知识图谱#ai_tec*]推理出新的实体间关系，可用于建立新知识或者对[$知识图谱#ai_tec*]进行逻辑的冲突检测。基于统计的方法一般指关系[$机器学习#ai_tec*]方法，即通过统计规律从[$知识图谱#ai_tec*]中学习到新的实体间关系。[@知识推理#ai_tec*]在知识计算中具有重要作用，如知识分类、知识校验、知识链接预测与知识补全等。（1）基于符号的并行[$知识推理#ai_tec*]基于多核、多处理器技术的大规模推理：单机环境下的并行技术以共享内存模型为特点，侧重于提升本体推理的时间效率，适用于对于实时性要求较高的应用场景，这种方法成为首选。对于表达能力较低的语言，比如 RDFS、OWL EL，单机环境下的并行技术显著地提升了本体推理效率。基于分布式技术的大规模推理：基于分布式技术可以突破大规模数据的处理界限，这种方法利用多机搭建集群来实现本体推理，很多工作基于 MapReduce的开源实现设计提出了大规模本体的推理方法，其中较为成功的一个尝试是 [@Urbani#Person*]等人在 2010年公布的[@推理系统#ai_product*] [@WebPIE#ai_product*]，在大集群上可以完成上百亿的 RDF三元组的推理，利用 MapReduce来实现 OWL EL本体的推理算法证明 MapReduce技术同样可以解决大规模的 OWL EL本体推理并在后续工作中进一步扩展，从而使得推理可以在多个并行计算平台完成。（2）链接预测基于表示学习的方法：[$知识图谱#ai_tec*]表示学习旨在于将[$知识图谱#ai_tec*]中的实体与关系统一映射至低维连续向量空间，以刻画它们的潜在语义特征。通过比较实体与关系在该向量空间中的分布式表示，可以推断出实体和实体之间潜在的关系。基于 ILP的模式归纳方法：基于 ILP述。Jens Lehmann等提出用向下精化算子学习 ALC的概念定义公理的方法，并在后续工作中将原有方法扩展到处理大规模知识库上。相关的算法都在本体学习工具 DL-Learner中得到实现，并且在工作中得到进一步扩展，涉及到框架的设计和可扩展性的提升等方面。基于关联规则挖掘的[@模式归纳方法#ai_tec*]：利用谓词偏好因子度量方法以及谓词语义相似度学习相反和对称公理；利用模式层信息给规则的挖掘提供更多的语义；对传统关联规则挖掘技术进行了改进，事务表中用 0到 1之间的一个实数代替原来的 0或者 1，使得提出的方法更符合语义数据开放的特点。基于[$机器学习#ai_tec*]的[$模式归纳方法#ai_tec*]：利用聚类的算法学习关系的定义域和值域；应用统计的方法过滤属性的使用，并找出准确、健壮的模式，用于学习属性的数量约束公理。 2.4.2.[@知识存储#ai_tec*]和查询[$知识图谱#ai_tec*]以图（ Graph）的方式来展现实体、事件及其之间的关系。[$知识图谱#ai_tec*]存储和查询研究如何设计有效的存储模式支持对大规模图数据的有效管理，实现对[$知识图谱#ai_tec*]中知识高效查询。（1）基于关系数据模型的 RDF数据存储和查询简单三列表：系统通过维护一张巨大的三元组表来管理 RDF数据。这张三元组表包含三列，对应存储主体、谓词和客体（或者主体、属性和属性值）。当系统接收到用户输入的 SPARQL查询时，这些系统将 SPARQL查询转化为 SQL查询。然后根据所得 SQL查询，这些系统通过对三元组表执行多次自连接操作以得到最终解。水平存储：将[$知识图谱#ai_tec*]中的每一个 RDF主体（subject）表示为数据库表中的一行。表中的列包括该 RDF数据集合中所有的属性。这种的策略的好处在于设计简单，同时很容易回答面向某单个主体的属性值的查询，即[@星状查询#ai_tec*]。存储方法的缺点也是很明显的：其一，表中存在大量的列；其二，表的稀疏性问题；其三，水平存储存在多值性的问题；其四，数据的变化可能带来很大的更新成本。属性表：为降低自连接操作次数， Jena和 Oracle在单张大三元组表之外还支持利用属性表进行 RDF数据管理。具体而言， [@Jena#Person*]通过聚类的方式将一些类似的三元组聚类到一起，这种方式下的属性表也被称之为聚类属性表；而 Oracle利用 RDF资源的类型信息将三元组进行分类，相同类的三元组放到具体而言， SW-Store将 RDF三元组按照谓词（或属性）的不同分成不同的表，每张表能保全索引策略：简单的三列表存储的缺点在于自连接次数较多。为了提高简单三列表存储的查询效率，目前一种普遍被认可的方法是“全索引（ exhaustive indexing）”策略。（2）基于图模型的 RDF数据存储和查询 RDF数据的图模型可以最大限度的保持 RDF数据的语义信息，也有利于对语义信息的查询。在这种情况下， SPARQL查询就可以视为在 RDF数据图上进行子图匹配运算。子图匹配运算是图数据库中一个比较经典的问题：其问题定义在于给定一个数据图和一个查询图，找出数据上所有与查询图子图同态的位置。这个问题已被证明是一个 NP难问题。针对 RDF数据的 SPARQL查询已经有一些基于图模型的查询处理系统，如 gStore、和 TurboHOM++。它们都是利用 RDF数据图的特点来构建索引。 2.4.3.知识查询与推理人才介绍选取 knowledge management、knowledge storage、knowledge storing、graph database、triple store、knowledge query、knowledge graph query、knowledge validation、knowledge evaluation、 knowledge conflict、knowledge consistency、ontology evaluation、ontology refinement、description logic、rule extraction、rule learning、knowledge inference、knowledge reasoning、patterning learning、 reasoner等词作为知识查询与推理领域关键词，按照图 2所示流程将所选学者定义为该领域知名学者并对其进行统计分析，最终绘制出该领域全球知名学者分布图，分别如图 21、图 22所示：图 21知识查询与推理领域全球知名学者分布图图 22知识查询与推理领域全球知名学者分布统计由以上两图可知，全球范围内，符合筛选条件的知识查询与推理领域知名学者集中分布在欧洲及北美洲，亚洲次之，大洋洲、南美洲较为匮乏。若按国家进行统计，[$美国#Gep*]是该领域学者最为集中的国家，境内学者数量多集中分布在东海岸，德国、中国、英国等国家学者数量次之，其他国家人数较少。图 23知识查询与推理领域中国知名学者分布图对符合上述条件的我国知识查询与推理领域学者分布进行分析，绘制中国范围内知识查询与推理领域知名学者分布图，如图 23所示。由图可知，中国知识查询与推理领域知名学者人数较少，境内学者在东北地区、环渤海经济圈、华东地区以及港澳地区均有分布，整体分布较为均匀。对知识查询与推理领域知名学者进行计算分析，最终绘制出该领域各国人才迁徙图，整体情况图 24所示：分布图，如图 25所示：350294 300 250 200 150 100 50 0 图 25知识查询与推理领域全球知名学者 h-index分布图根据统计信息及上图数据显示可知，[$知识融合#ai_tec*]领域学者 h-index分布呈现金字塔结构，大部分学者 h-index分布在整体的中下区域，其中 h-index在＜10区间的数量最多，位于整体中部的 10~20区间、 20~40区间学者数量相差不大， h-index＞60的顶尖学者数量最少，由此可见，知识查询与推理领域顶尖学者与知名学者无论是数量还是研究质量均存在较大差距。 ＜10 10~20 20~40 40~60＞60 受限于机器挖掘算法、原始数据信息与本报告篇幅， AMiner仅选取该领域不同国籍的典型学者做简单介绍，此次排序不分先后。 Frank Wolter 会议等顶级学术会议最佳论文奖等奖项以及 2018年 KR主席、2019年 AAAI高级会士等荣誉。 Frank Wolter的高引用论文是 2003年发表在 IEEE上的“ E-connections of abstract description systems”认为优秀的 AI应用程序包含了现实世界中的不同方面，因此需要对每一个方面进行建模的