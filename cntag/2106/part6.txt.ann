网络的摄影、图像处理应用能够为用户提供更加完美的体验，图17 显示了 Mate10 的成像效果对比图。 图 17 华为 Mate10 成像效果对比图 2017 年 9 月中旬，[@苹果#Org*]发布以iPhone X 为代表的手机及它们内置的 [@A11 Bionic 芯片#ai_product*]。31A11 Bionic 中自主研发的双核架构 [@Neural Engine#ai_tec*]（神经网络处理引擎），它每秒处理相应神经网络计算需求的次数可达6000 亿次。这个 [$Neural Engine#ai_tec*] 的出现，让[@A11 Bionic#ai_product*] 成为一块真正的[@AI 芯片#ai_product*]。[@A11 Bionic#ai_product*] 大大提升了iPhone X 在拍照方面的使用体验，并提供了一些富有创意的新用法。如更具革命性的 FaceID，它能够将传感器数据进行实时3D建模，并利用机器学习识别用户容貌改变，在此过程中的大量计算需求，都需要借助 [@A11Bionic#ai_product*] 和[$Neural Engine#ai_tec*] 来满足，如图18 所示。除此之外，[$A11 Bionic#ai_product*] 内置了[$苹果#Org*]自主设计的第一款GPU。这款 GPU 是为3D 游戏和 [@Metal 2#ai_tec*]（[$苹果#Org*]在WWDC [@2017#Date*]上推出的新一代图像渲染技术框架）专门设计的，并且能够与[@机器学习技术#ai_tec*]和[$苹果#Org*]随 iOS 11 推出的[@Core ML#ai_tec*]（核心机器学习）框架相配合。图 18 [$苹果#Org*]的Face ID [@谷歌#Org*]，[@高通#Org*]同样在随后发布的产品中植入AI 芯片，或许这将成为业界的一个新趋势，即使因为植入 [@AI 芯片#ai_product*]能为用户带来真正美好体验，还需要等到有足够多的基于[@深度学习#ai_tec*]的APP 出现才可实现。 （2）[@ADAS#ai_product*]（高级辅助驾驶系统） [@ADAS#ai_product*]是最吸引大众眼球的人工智能应用之一，它需要处理海量的由激光雷达、毫米波雷达、摄像头等传感器采集的实时数据。[$ADAS#ai_product*] 的中枢大脑——[$ADAS#ai_product*] 芯片市场的主要厂商包括被[@英特尔#Org*]收购的 [@Mobileye#Org*]、[$2017#Date*] 年被[$高通#Org*]以 470 亿美元惊人价格收购的 [@NXP#Org*]，以及汽车电子的领军企业[@英飞凌#Org*]。随着[@英伟达#Org*]推出自家基于 GPU的[$ADAS#ai_product*]解决方案 [@Drive PX2#ai_tec*]，英伟达也加入到战团之中。 相对于传统的车辆控制方法，[@智能控制方法#ai_tec*]主要体现在对控制对象模型的运用和综合32信息学习运用上，包括[@神经网络控制#ai_tec*]和[@深度学习方法#ai_tec*]等，得益于 [@AI 芯片#ai_product*]的飞速发展，这些算法已逐步在车辆控制中得到应用。 （3）[@CV#ai_tec*]（计算机视觉（Computer Vision））设备 需要使用[@计算机视觉技术#ai_tec*]的设备，如[@智能摄像头#ai_product*]、[@无人机#ai_product*]、[@行车记录仪#ai_product*]、[@人脸识别迎宾机器人#ai_product*]以及[@智能手写板#ai_product*]等设备，往往都具有本地端推断的需要，如果仅能在联网下工作，无疑将带来糟糕的体验。而[@计算机视觉技术#ai_tec*]目前看来将会成为[@人工智能#ai_tec*]应用的沃土之一，计算机视觉芯片将拥有广阔的市场前景。 计算机视觉领域全球领先的芯片提供商 Movidius，目前已被英特尔收购，[@大疆#Org*][@无人机#ai_product*]、[@海康威视#Org*]和[@大华股份#Org*]的[@智能监控摄像头#ai_product*]均使用了 [@Movidius#Org*] 的 [@Myriad 系列芯片#ai_product*]。 目前国内做[$计算机视觉技术#ai_tec*]的公司以初创公司为主，如[@商汤科技#Org*]、[@阿里系旷视#Org*]、[@腾讯优图#Org*]，以及[@云从#Org*]、[@依图#Org*]等公司。在这些公司中，未来有可能随着其自身[$计算机视觉技术#ai_tec*]的积累渐深，部分公司将会自然而然转入 [$CV#ai_tec*] 芯片的研发中，正如Movidius 走的也是从[$计算机视觉技术#ai_tec*]到芯片研发的路径。 （4）[@VR 设备#ai_tec*] VR 设备芯片的代表为 [@HPU 芯片#ai_product*]，是[@微软#Org*]为自身 VR设备[@Hololens#ai_product*] 研发定制的。这颗由台积电代工的芯片能同时处理来自5 个摄像头、1个深度传感器以及运动传感器的数据，并具备[@计算机视觉#ai_tec*]的矩阵运算和[@CNN运算#ai_tec*]的加速功能。这使得 [$VR 设备#ai_tec*]可重建高质量的人像3D 影像，并实时传送到任何地方。 （5）语音交互设备 语音交互设备芯片方面，国内有[@启英泰伦#Org*]以及[@云知声#Org*]两家公司，其提供的芯片方案均内置了为[@语音识别#ai_tec*]而优化的[@深度神经网络加速方案#ai_tec*]，实现设备的语音离线识别。稳定的识别能力为语音技术的落地提供了可能；与此同时，语音交互的核心环节也取得重大突破。[@语音识别#ai_tec*]环节突破了单点能力，从[@远场识别#ai_tec*]，到[@语音分析#ai_tec*]和[@语义理解#ai_tec*]有了重大突破，呈现出一种整体的交互方案。 [@语音交互#ai_tec*]正在悄悄改变人们的家居生活习惯，如居于客厅核心位置的[@智能电视#ai_product*]，越来越多的消费者习惯在沙发上使用语音换台，语音作为智能家居入口将有广阔的想象空间。 （6）[@机器人#ai_tec*] 无论是家居机器人还是商用服务机器人均需要专用软件+芯片的[@人工智能#ai_tec*]解决方案，这方面典型公司有由前[@百度#Org*][$深度学习#ai_tec*]实验室负责人[@余凯#Person*]创办的地平线机器人，当然地平线机器人除此之外，还提供 [$ADAS#ai_product*]、[@智能家居#ai_product*]等其他嵌入式[$人工智能#ai_tec*]解决方案。 在移动端推断领域，呈现给我们的是一个缤纷的生态。因为无论是[$ADAS#ai_product*]还是各类[$CV#ai_tec*]、[@33VR#ai_tec*] 等设备领域，[@人工智能#ai_tec*]应用仍远未成熟，各[$人工智能#ai_tec*]技术服务商在深耕各自领域的同时，逐渐由[$人工智能#ai_tec*]软件演进到软件+芯片解决方案是自然而然的路径，因此形成了丰富的芯片产品方案。 346 趋势篇 目前主流[$AI 芯片#ai_product*]的核心主要是利用MAC（Multiplier and Accumulation，乘加计算）加速阵列来实现对[@CNN#ai_tec*]（[@卷积神经网络#ai_tec*]）中最主要的卷积运算的加速。这一代 [$AI 芯片#ai_product*]主要有如下3 个方面的问题。 （1）[$深度学习#ai_tec*]计算所需数据量巨大，造成内存带宽成为整个系统的瓶颈，即所谓“memory wall”问题。 （2）与第一个问题相关，内存大量访问和MAC 阵列的大量运算，造成[$AI 芯片#ai_product*]整体功耗的增加。 （3）[$深度学习#ai_tec*]对算力要求很高，要提升算力，最好的方法是做硬件加速，但是同时[$深度学习#ai_tec*]算法的发展也是日新月异，新的算法可能在已经固化的硬件加速器上无法得到很好的支持，即性能和灵活度之间的平衡问题。 因此，我们可以预见，下一代 [$AI 芯片#ai_product*]将有如下的几个发展趋势。 趋势一：更高效的大卷积解构/复用 在标准SIMD 的基础上，[$CNN#ai_tec*] 由于其特殊的复用机制，可以进一步减少总线上的数据通信。而复用这一概念，在超大型神经网络中就显得格外重要。如何合理地分解、映射这些超大卷积到有效的硬件上成为了一个值得研究的方向，如图19 所示。图 19 分解卷积可降低消耗 趋势二：更低的 Inference 计算/存储位宽[$AI 芯片#ai_product*]最大的演进方向之一可能就是[@神经网络#ai_tec*]参数/计算位宽的迅速减少——从 32 位36浮点到16 位浮点/定点、8 位定点，甚至是 4 位定点。在理论计算领域，2 位甚至1 位参数位宽，都已经逐渐进入实践领域，如图 20 所示。 图 20 逐层动态定点方法 趋势三：更多样的存储器定制设计 当计算部件不再成为[$神经网络#ai_tec*]加速器的设计瓶颈时，如何减少存储器的访问延时将会成为下一个研究方向。通常，离计算越近的存储器速度越快，每字节的成本也越高，同时容量也越受限，因此新型的存储结构也将应运而生。 趋势四：更稀疏的大规模向量实现 图 21 五级流水线结构 [$神经网络#ai_tec*]虽然大，但是，实际上有很多以零为输入的情况，此时稀疏计算可以高效的减少无用能效。来自哈佛大学的团队就该问题提出了优化的五级流水线结构，如图 21 所示，在最后一级输出了触发信号。在Activation 层后对下一次计算的必要性进行预先判断，如果发现这是一个稀疏节点，则触发SKIP 信号，避免乘法运算的功耗，以达到减少无用功耗的37目的。 趋势五：计算和存储一体化 计算和存储一体化（process-in-memory）技术，其要点是通过使用新型非易失性存储（如 ReRAM）器件，在存储阵列里面加上[$神经网络#ai_tec*]计算功能，从而省去数据搬移操作，即实现了计算存储一体化的[$神经网络#ai_tec*]处理，在功耗性能方面可以获得显著提升。38 