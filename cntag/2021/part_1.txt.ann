[@美国美国国防预先研究计划局#Org*]（[@DARPA#Org*]）正在开展[@“可解释人工智能”计划（XAI）#ai_program*]，以此探索可以使[@自主系统#ai_product*]对其行为进行更好的解析的技术。[$DARPA#Org*]已经确定，在[$自主系统#ai_product*]向分析师提供有关可疑活动的信息或需要进一步检查的情况下，分析人员有必要让[$自主系统#ai_product*]解释为什么要执行例如将特定照片、数据或特定的人带给分析人员这样的行为。按照[$DARPA#Org*]的设想，[@XAI#ai_program*]的目标是“产生更多可解释的模型，同时保持高水平的学习表现（预测准确性）；使人类用户理解、适当、信任和有效地管理[@新一代人工智能#ai_tec*]合作伙伴”。