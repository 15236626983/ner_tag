人工智能之情感计算1 概述篇 1.1 情感计算的产生及发展 40多年前，诺贝尔奖得主Herbert Simon在认知心理学方面强调，解决问题论要结合情感的影响。情感的识别和表达对于信息的交流和理解是必需的，也是人类最大的心理需求之一。人类的认知、行为等几乎都要受到情感的驱动，并影响着人际互动以及群体活动。在人与人的交往中，情感的交流还常被用来完成人的意图的传递。因此，在智能人机交互的研究中，拥有对情感的识别、分析、理解、表达的能力也应成为智能机器必不可少的一种功能。作为人工智能创始人之一的美国麻省理工学院Marvin Minsky教授首次提出让计算机具有情感的能力，他在其专著《The Society of Mind》中强调情感是机器实现智能不可或缺的重要能力。20世纪90年代初，耶鲁大学心理学系的Peter Salovey教授提出了情感智能的概念，并开展了一系列的研究。该概念随后被Daniel J. Goleman发展为与智商（IQ）相对的情商（EQ），随着Goleman的赋予计算机情感能力，并让计算机能够理解和表达情感的探讨与研究引起了计算机界众多专家的兴趣，他们在情感研究的理论和实验应用方面积累了很多经验。 学术界较早对情感进行系统研究的是美国麻省理工学院媒体实验室的Rosalind W. Picard教授。1995年，Picard首先提出通过识别人体的情感信号，来创建一种能够感知、识别和理解人的情感，并且能够做出智能、灵敏和友好反应的计算机系统。1997年，Picard出版专著《Affective Computing》，书中给出了情感计算的定义，即情感计算是关于情感、情感产生以及影响情感方面的计算，并对情感计算的研究做了系统介绍。情感赋予计算机像人一样的观察、理解和生产各种情感特征的认知能力。在情感表达和识别方面，随着多媒体技术和人工智能技术的不断发展和广泛应用，机器的识别水平在不远的将来一定会有长足的进步。 日本在20世纪70年代提出了“感性工学”的概念，在文部省主导下，日本从20世纪90年代开始了对感性工学的研究。所谓感性工学，就是将感性与工程结合起来的技术，是在感性科学的基础上，通过分析人类的感性，把人的感性需要加入到商品设计和制造中去，它是一门从工程学角度研究能带给人喜悦和满足的商品制造的技术科学。日本在人工智能、心理学、认知、情报处理等方面都展开了相关的研究。其中之一是由筑波大学原田昭教授主持的一个超大型特别研究项目——“感性评价构造模式的构筑”。这一计划从1997年7月启动，为期三年，集中了约50位各国研究人员，包括工业设计、机器人工程、控制工程、资讯工程、信息管理、认知科学、美学、艺术等众多领域的专家团队，分为感性评价、程序与感性数据库和机器人系统三组。该计划在全球几个重要的美术馆，设置附有摄影机的机器人；然后让受测者在其他地方，通过网际网络计算机联机，远距离遥控机器人来观赏艺术品；对于受测者操纵机器人的整个过程，进行纪录并分析整理，以了解观赏者在鉴赏艺术品时，如何建立其感性评价的心理机制。 欧盟国家也在积极地对情感信息处理技术（表情识别、情感信息车辆、可穿戴计算等）展开研究。欧洲许多大学成立了情感与智能关系研究小组，其中较为著名的有日内瓦大学Klaus Soberer领导的情绪研究实验室、布鲁塞尔自由大学的D Canamero领导的情绪机器人研究小组以及英国伯明翰大学的A Sloman领导的Cognition and Affect Project。在市场应用方面，德国Mehrdad Jaladi-soli等在2001年提出了基于Embassi系统的多模型购物助手。Embassi是由德国教育及研究部（BMBF）资助并由20多个大学和公司共同参与的，以考虑消费者心理和环境需求为研究目标的网络型电子商务系统。 我国对人工情感和认知的研究始于20世纪90年代，并逐步得到重视。国家自然科学基金早在1998年就将和谐人机环境中的情感计算理论研究列为当年信息技术高技术探索第六主题。2003年12月，在北京召开了第一届中国情感计算及智能交互学习会议，标志着国内学术界对情感信息处理研究的肯定和认同。2004年，国家自然科学基金委批准资助了重点基金项目情感计算理论与方法。这标志着我国在人工情感领域的研究达到了一个新的水平，呈现出方兴未艾的发展势头，研究队伍迅速扩大，研究领域急速拓展。2005年9月，我国40多名专家教授在北京召开了中国人工智能学会首届全国人工心理与人工情感学术会议，并倡议成立中国人工智能学会人工心理与人工情感专业委员会，开展相关方面的学术活动。2005年10月，中国人工智能学会同意并上报国家民政部，批准成立了中国人工智能学会人工心理与人工情感专业委员会。随后，人工心理与人工情感专业委员会及其成员组织召开了全国第一届人工心理与人工情感学会会议（北京科技大学，2005）和首届国际情感计算与人机交互国际会议（中科院自动化所，2005）[1] 。2007年12月，中国人工智能学会人工心理与人工情感专业委员会在哈尔滨CAAI-12届年会上举行了正式成立大会，这是国内在电子信息科学领域的首个情感计算学会。学会集合了国内一流的人工心理与人工情感的研究专家，他们获得了第一个关于人工情感计算的国家自然科学重点基金（清华大学）；第一个“973”项目中的和谐人机交互理论与技术的研究课题（中科院软件所）。随着研究的不断深入，关于人工情绪和情感计算的课题越来越多。 1.2 概念定义 1.2.1 情感 情感（emotion）一词源于希腊文“pathos”，最早用来表达人们对悲剧的感伤之情。达尔文（Darwin）认为，情感源于自然，存活于身体中，它是热烈的、非理性的冲动和直觉，遵循生物学的法则。理智则源于文明，存活于心理。《心理学大辞典》将情感定义为“人对客观事物是否满足自己的需要而产生的态度体验”。Antonio Damasio在其神经生物学研究结果的基础上将情感至少分为两类，即原发性情感和继发性情感。原发性情感被认为是与生俱来的，被理解为一岁儿童情感这种典型的情感类型，继发性情感被假设为从更高的认知过程中产生。而James Russell)则从两个方面构造情感：核心情感和心理建构，前者表示神经系统的状态，如昏昏欲睡；后者表示行动，如面部表情、音调，以及行动之间的关联。由于情感的复杂性，研究情感的相关学者对情感的定义至今也未达成一致，记载的相关理论就有150多种。 而“emotion”一词由前缀“e”和动词“move”结合而来，直观含义是从一个地方移动到另一个地方，后来逐渐被引申为扰动、活动，直到近代心理学确立之后，才最终被詹姆斯（William James）用来表述个人精神状态所发生的一系列变动过程。Picard曾在其书中专门对情感和情绪方面术语进行了区分，她认为相对情感而言，情绪表示一个比较长的情感状态。情感影响我们的态度、情绪和其他感觉、认知功能、行为以及心理。同时情感容易在多次情绪体验的基础上实现，当人们多次觉得完成一项任务很高兴，就会爱上这个任务。相比情绪而言，情感更具有深刻性和稳定性。在自然语言处理中，Myriam D等人结合韦氏字典以及他们的相关研究得到的结论是，在语言中情感是无意识的，并且很难将其定义，从文本中可以检测到的是有意识的情感，是情绪表征。而情绪这一复杂心理学现象几乎不能从文本中全部检测出，能检测到的是情绪的构成因素。许多关于情感计算的研究并没有完全区分情绪和情感（包括本文引用的大部分论文），本文统一使用“情感”一词。 情感具有三种成分： . 主观体验，即个体对不同情感状态的自我感受； . 外部表现，即表情，在情感状态发生时身体各部分的动作量化形式。表情包括面部表情（面部肌肉变化所组成的模式）、姿态表情（身体其他部分的表情动作）和语调表情（言语的声调、节奏、速度等方面的变化）； . 生理唤醒，即情感产生的生理反应，是一种生理的激活水平，具有不同的反应模式。 1.2.2 情感计算 让计算机具有情感能力的观点并不新鲜，它与“机器人”一词几乎同时出现。1985年，人工智能的奠基人之一Minsky就明确指出：“问题不在于智能机器能否有情感，而在于没有情感的机器能否实现智能”。但当时，赋予计算机或机器人以人类式的情感，主要还是科幻小说中的素材，在学术界罕有人关注。1995年情感计算的概念由Picard首次提出，并于1997年正式出版《Affective Computing（情感计算）》。在书中，她指出“情感计算就是针对人类的外在表现，能够进行测量和分析并能对情感施加影响的计算”，开辟了计算机科学的新领域，其思想是使计算机拥有情感，能够像人一样识别和表达情感，从而使人机交互更自然。 情感研究可以从两个方面来理解，一是基于生理学的角度，通过各种测量手段来记录人体的各种生理参数，比如，人体运动数据，脸部表情、心理、脉搏、脑电波等，并以此为根据来计算人体的情感状态；二是基于心理学的角度，通过各种传感器接收并处理信息，并以此为根据计算人造机器所处的情感状态。Picard以人类情绪的生理信号处理为基本出发点，研究取得了诸多进展，其应用领域也在逐渐扩大。当然，并不是所有的研究者都同意Picard的想法。例如Sengers、Gaver、Dourish和Kristina Hook等学者借鉴现象学并且把情感看作人与人、人与机互动中的成分。情感互动方法认为应从一个对情感建设性的、人文决定性视角展开，而非从认知和生物学这一更传统的角度出发，这种方法将重点放在使人们获得可以反映情感的体验并以某种方式来修改他们的反应。 简单来说，情感计算研究就是试图创建一种能感知、识别和理解人的情感，并能针对人的情感做出智能、灵敏、友好反应的计算系统。显然，情感计算是个复杂的过程，不仅受时间、地点、环境、人物对象和经历的影响，而且要考虑表情、语言、动作或身体的接触。在人机交互中，计算机需要捕捉关键信息，觉察人的情感变化，形成预期，进行调整，做出反应。例如通过对不同类型的用户建模（如操作方式、表情特点、态度喜好、认知风格、知识背景等），以识别用户的情感状态，利用有效的线索选择合适的用户模型，并以适合当前用户的方式呈现信息。在对当前的操作做出及时反馈的同时，还要对情感变化背后的意图形成新的预期，并激活相应的数据库，及时主动地提供用户需要的新信息。举例来说，麻省理工学院媒体实验室的情感计算小组研制的情感计算系统通过记录人面部表情的摄像机和连接在人身体上的生物传感器来收集数据，然后由一个“情感助理”来调节程序以识别人的情感。假设你对电视讲座的一段内容表现出困惑，情感助理会重放该片段或者给予解释。而目前国内情感计算的研究重点在于通过各种传感器获取有人的情感所引起的生理及行为特征信号，确定情感类别的关键特征，建立“情感模型”，从而创建个人情感计算系统。 情感计算是一个高度综合化的研究和技术领域。通过计算科学与心理科学、认知科学的结合，研究人与人交互、人与计算机交互过程中的情感特点，设计具有情感反馈的人与计算机的交互环境，将有可能实现人与计算机的情感交互。情感计算研究将不断加深对人的情感状态和机制的理解，并提高人与计算机界面的和谐性，即提高计算机感知情境，理解人的情感和意图，做出适当反应的能力，其主要研究内容如下图所示：  图 1 情感计算的研究内容 1.2.2.1 情感信号的采集 情感信号的获取研究主要是指各类有效传感器的研制。它是极为重要的环节，没有有效的传感器，就没有情感计算的研究，因为情感计算的所有研究都是基于传感器所获得的信号。各类传感器应具有如下的基本特征：使用过程中不影响用户（如重量、体积、耐压性等），经过医学检验对用户无伤害；数据的隐私性、安全性和可靠性；传感器价格低、易于制造等。美国麻省理工学院媒体实验室的传感器研制较为先进，已研制出多种传感器，如脉压传感器、皮肤电流传感器、汗液传感器及肌电流传感器等。其中，皮肤电流传感器可实时测量皮肤的导电系数，通过导电系数的变化可测量用户的紧张程度；脉压传感器可时刻监测由心率变化而引起的脉压变化；汗液传感器是一条带状物，可通过其伸缩的变化时刻监测呼吸与汗液的关系；肌电流传感器可以测得肌肉运动时的弱电压值。 情感信号的获取必须通过一定形式的情感测量技术来完成，情感测量包括对情感维度、表情维度和生理指标三种成分的测量。例如，我们要确定一个人的焦虑水平，可以使用问卷测评其主观感受，通过记录和分析面部肌肉活动测量其面部表情，并用血压计测量血压，对血液样本进行化验，检测血液中肾上腺素水平等。确定情感维度对情感测量有重要意义，因为只有确定了情感维度，才能对情感体验做出较为准确的评估。情感维度具有两极性，例如，情感的激动性可分为激动和平静两极，激动指的是一种强烈的、外显的情感状态，而平静指的是一种平稳、安静的情感状态。心理学的情感维度理论认为，几个维度组成的空间包括了人类所有的情感。但是，情感究竟是二维，三维，还是四维，研究者们并未达成共识。情感的二维理论认为，情感有两个重要维度：一是愉悦度，通过惊反射的方式测量其生理指标；二是激活度，通过皮肤电反应方式测量其生理指标。 1.2.2.2 情感信号的分析、建模与识别 一旦各类有效传感器获得了情感信号，下一步就是将情感信号与情感机理相应方面的内容对应起来，这里要对所获得的信号进行建模和识别。由于情感状态是一个隐含在多个生理和行为特征之中的不可直接观测的量，不易建模，部分可采用诸如隐马尔可夫模型、贝叶斯网络模式等数学模型。美国麻省理工学院媒体实验室给出了一个隐马尔可夫模型，可根据人类情感概率的变化推断得出相应的情感走向。 计算机对从传感器采集来的信号进行分析和处理，从而得出对方（人）正处在的情感状态，这种行为叫做情感识别。从生理心理学的观点来看，情绪是有机体的一种复合状态，既涉及体验又涉及生理反应，还包含行为，其组成至少包括情绪体验、情绪表现和情绪生理三种因素。目前对于情感识别有两种方式，一种是检测生理信号如呼吸、心律和体温等，另一种是检测情感行为如面部特征表情识别、语音情感识别和姿态识别。 . 人脸情感识别 在生活中，人们很难保持一种僵硬的脸部表情，通过脸部表情来体现情感是人们常用的较自然的表现方式，其情感表现区域主要包括嘴、脸颊、眼睛、眉毛和前额等。人在表达情感时，只稍许改变一下面部的局部特征（譬如皱一下眉毛），便能反映一种心态。1972年，著名学者Ekman提出了脸部情感的表达方法（脸部运动编码系统FACS），通过不同编码和运动单元的组合，即可以在脸部形成复杂的表情变化，譬如幸福、愤怒、悲伤等。该成果已经被大多数研究人员所接受，并被应用在人脸表情的自动识别与合成方面。随着计算机技术的飞速发展，为了满足通信的需要，人们进一步将人脸识别和合成的工作融入到通信编码中。最典型的便是MPEG4 V2视觉标准，其中定义了3个重要的参数集：人脸定义参数、人脸内插变换和人脸动画参数。表情参数中具体数值的大小代表人激动的程度，可以组合多种表情以模拟混合表情。在目前的人脸表情处理技术中，多侧重于对三维图像更加细致的描述和建模。通常采用复杂的纹理和较细致的图形变换算法，达到生动的情感表达效果。在此基础上，不同的算法形成了不同水平的应用系统。 随着人脸的计算机处理技术（包括人脸检测和人脸识别）不断完善，利用计算机进行面部表情分析也就成为可能。由于各种面部表情本身体现在各个特征点运动上的差别并不是很大，而表情分析对于人脸的表情特征提取的准确性和有效性要求比较高，因而难以顺利地实现。具体的表情识别方法主要有三个：一是整体识别法和局部识别法，二是形变提取法和运动提取法，三是几何特征法和容貌特征法。当然，这三个发展方向不是严格独立的，恰恰相反，它们是相互联系和影响的，它们从不同侧面提取所需要的表情特征，都只是提供了一种分析表情的思路。例如：嘴巴张开并不代表就是笑，也有可能是哭和惊讶等。所用到的识别特征主要有：灰度特征、运动特征和频率特征三种。灰度特征是从表情图像的灰度值上来处理，利用不同表情有不同灰度值来得到识别的依据；运动特征利用了不同表情情况下人脸的主要表情点的运动信息来进行识别；频域特征主要是利用了表情图像在不同的频率分解下的差别，速度快是其显著特点。 通常根据视频识别要比根据静态图像识别更准确，视频能捕捉某种表情形成过程的面部动作。当人通过视觉器官把他人面部的刺激信号接收并传递到人的大脑之中，大脑就会进行人脸检测、人脸图像预处理、人脸特征提取等程序，然后，把以前存储在大脑中的若干基本表情的人脸特征（即脸谱）提取出来，进行对比分析和模糊判断，找出两者的人脸特征最接近的某种基本表情。这时，大脑皮层就会接通该基本表情所对应的兴奋区与边缘系统的神经联系，从而产生愉快或痛苦的情感体验。同时，大脑皮层还会接通该基本表情所对应的兴奋区与网状结构的神经联系，从而确定愉快或痛苦的强度。 . 语音情感识别 在人类的交互过程中，语音是人们最直接的交流通道，人们通过语音能够明显地感受到对方的情绪变化，例如通过特殊的语气词、语调发生变化等等。在人们通电话时，虽然彼此看不到，但能从语气中感觉到对方的情绪变化。例如同样一句话“你真行”，在运用不同语气时，可以使之成为一句赞赏的话，也可以使之成为讽刺或妒忌的话。目前，国际上对情感语音的研究主要侧重于情感的声学特征分析这一方面。一般来说，语音中的情感特征往往通过语音韵律的变化表现出来。例如，当一个人发怒的时候，讲话的速率会变快，音量会变大，音调会变高等，同时一些音素特征（共振峰、声道截面函数等）也能反映情感的变化。语音情感识别是指由计算机自动识别输入语音的情感状态。不同语言声调表情的信号在其时间构造、振幅构造、基频构造和共振峰构造等特征方面也有着不同的构造特点和分布规律。只要把各种具体模式的语言声调表情在时间构造、振幅构造、基频构造和共振峰构造等方面的特点和分布规律进行测算和分析，并以此为基础或模板，就可以识别出所有语言声调中所隐含的情感内容。中国科学院自动化研究所模式识别国家重点实验室的专家们针对语言中的焦点现象，首先提出了情感焦点生成模型。这为语音合成中情感状态的自动预测提供了依据，结合高质量的声学模型，使得情感语音合成和识别率先达到了实际应用水平。 语音中的情感特征化比面部表情的情感特征化要难。面部表情信号传达了个人特征和表情，一般不传达语言信息。另一方面，语音信号包含的是混合信息，包括说话者特征、情感和说话内容中强调的词汇和语法。计算机在语音情感的识别和合成方面的进展很慢。随着计算机多媒体技术的不断发展，能处理包含在媒体中的情感信息的拟人化的多媒体计算机系统的研究越来越引起人们的兴趣。因为语音信号既是多媒体人机交互的主要利用方式，又是传载情感信息的重要媒体，所以对于包含在语音