内瓦发明奖1项。目前主要的研究方向包括数字媒体处理与检索、[@视频情感计算#ai_tec*]、[@增强现实#ai_tec*]、网络安全与大数据处理、多核计算计算与流编译和教育信息化等。 . 合肥工业大学情感计算与系统结构研究所 合肥工业大学情感计算研究所于2011年成立，主任为[@孙晓#Person*]教授。主要从事[@先进智能#ai_tec*]、[@情感计算#ai_tec*]、大规模数据与[@知识获取#ai_tec*]的基础理论研究工作。研究所构建了丰富的数据资源，包括文本语料库、面部表情库、动作-情感库等，其中全球最大规模的中文情感语料库，已授权全球近300家高校、科研机构使用。构建了基于大规模多源情感数据库的情感感知、推理与交互的总体研究思路与方法体系，取得了系列突破性研究成果，使我国在[$先进智能#ai_tec*]及情感机器人达到了世界先进水平。主持并参与国家973预研项目、863项目，国家自然科学基金项目、安徽省自然科学基金项目、企业委托项目等多项。[@2011年12月#Date*]获批建设“[$情感计算#ai_tec*]与[$先进智能#ai_tec*]机器安徽省重点实验室”，系统展开[$情感计算#ai_tec*]与[$先进智能#ai_tec*]机器的研究，是国内首个以[$情感计算#ai_tec*]命名的重点实验室。研究方向包括：[$情感计算#ai_tec*]；[@自然语言处理#ai_tec*]；[@听觉信息认知计算#ai_tec*]；[@视觉信息认知计算#ai_tec*]；[@情感可穿戴计算#ai_tec*]；[@机器人云理论#ai_tec*]及其应用。 . 东南大学情感信息处理实验室 东南大学情感信息处理实验室（Affective Information Processing Lab，AIPL）创建于2004年，隶属于东南大学生物科学与医学工程学院和儿童发展与学习科学教育部重点实验室（东南大学），任为郑文明。实验室深耕[$情感计算#ai_tec*]领域，主持包括973计划、国家自然科学基金重点项目在内的多项国家和省部级课题，在包括IEEE Transactions系列期刊和ICCV，PR，ECCV，NIPS，IJCAI和AAAI等计算机领域顶级会议上已发表论文百余篇，部分研究成果获国家技术发明二等奖1项（2018年）、教育部自然科学二等奖2项（2015年和2008年）和江苏省科技进步二等奖1项（2009年）。研究方向包括：[$情感计算#ai_tec*]、[@模式识别#ai_tec*]、[@计算机视觉#ai_tec*]和[@机器学习#ai_tec*]及其在儿童智能发展、教育和医疗等方面的应用研究。   内页背景2.jpg4 应用篇 近年来，Picard领导的[@美国#Gep*]麻省理工学院多媒体实验室相继提出了近50种[$情感计算#ai_tec*]应用项目。例如，将[$情感计算#ai_tec*]应用于医疗康复，协助自闭症者，识别其情感变化，理解患者的行为；在教育中应用[$情感计算#ai_tec*]，实现对学习状态的采集及分析，指导教学内容的选择及教学进度进行；还可以将[$情感计算#ai_tec*]应用于生活中，计算机能够感知用户对音乐的喜好，根据对情感反应的理解判断，为用户提供更感兴趣的音乐播放等。本篇将对[$情感计算#ai_tec*]在课堂教学、情感检测和医疗康复中的运用做详细介绍。 4.1 课堂教学 . 面部识别测量学生理解程度 在[$美国#Gep*]，公立学校的预算限制引发大规模的教师裁员和教室拥挤不堪。教师工作时间紧张，还要考虑和满足每个学生的需求。结果就是，那些课业困难的孩子容易受到忽视。因为只要孩子不提出问题，老师就不会关注到他。 在过去三年里，有企业把面部识别技术应用到了第一线教学当中。在SensorStar实验室，他们用相机捕捉学生上课反应，并且输入到计算机里面，运用算法来确定学生注意力是否转移。通过面部识别软件EngageSense，计算机能够测量微笑、皱眉和声音来测定学生课堂参与度。孩子们的眼睛是专注于老师的吗？他们是在思考还是发呆？他们是微笑还是皱着眉头？或者他们只是觉得困惑？还是无聊？测量之后，老师将会收到一份反馈报告，基于面部分析，报告会告诉老师他们的学生学习兴趣何时最高、何时最低。这样，老师能够对自己的教学方案做出调整，满足更多学生的需求。此外，比尔和梅林达盖茨基金会资助了[@传感器手镯#ai_product*]（sensor bracelets）的开发，这可以用来追踪学生的参与水平。腕部设备能够发送小电流，通过在神经系统响应刺激时测量电荷的细微变化便可以得知学生的课程兴奋程度。 心理学家Paul Ekman将面部识别技术研究提升到了一个新的层次。他对5000多种面部运动进行了分类，以帮助识别人类情绪。他的研究为Emotient Inc、Affectiva Inc和Eyeris等公司提供了帮助，这些公司将心理学和数据挖掘相结合，检测人的细微表情，并对人的反应进行分类。目前为止，面部识别技术的重点是协助联邦执法和市场调研。不过，圣地亚哥市的研究人员也在医疗行业试用这项技术，测定孩子接受外科手术之后的疼痛程度[13] 。 . [$机器学习#ai_tec*]定制学生课堂学习内容 TechCrunch公司的员工设计了在线教育平台，来提供一对一指导和精熟学习（mastery learning）。这是应用创新型思维，通过实时的评估和定制化的学习方式，有效地解决本杰明提出的著名的“Sigma 2 Problem”。[@深度学习#ai_tec*]系统将学生学习效果数据进行分类，并且在此基础上制定相关的教学内容。该系统还可以推荐附加练习，并且根据学生个人能力和教学要求，实时推荐课程内容，调整教学速度[14] 。 北卡罗来纳州州立大学研究员开发了一种软件，通过摄像头捕捉和分析学生面部表情，以此改变在线课程。目前，大多数[$情感计算#ai_tec*]技术还仅仅停留在学术研究领域。但也已经有公司开始应用这项技术，并能成功地分辨学生表情，并根据他们的学习能力和方式，来自动调整适合的学习内容和环境。英特尔公司正是这其中的一员。有了这些学生表情数据，可以让“Emoshape”这样的[$情感计算#ai_tec*]智能系统，自动分析情感，并做出适当回复。这些系统具备了解决个体问题的能力，也使老师能够提供高度个性化的内容来激发学生的学习兴趣。 人工智能和大数据已经促成了大部分行业的技术革新，从电子商务到交通、金融、医疗。[@人工智能#ai_tec*]和大数据已经在教育方面取得进展。尽管有些反对的声音，比如说如何保护学生隐私、如何提高教学效率等，但需要指出的是，这些技术的应用并不是要代替老师，而是扮演辅助老师的角色，识别学生的个体需求，以制定更加智能的教学方案。 4.2 情绪监测 为了深度挖掘人类情感的奥秘，[$美国#Gep*]麻省理工学院计算机科学与[$人工智能#ai_tec*]实验室打造了用无线信号监测情绪的[@EQ-Radio#ai_product*][15] 。在没有身体感应器和面部识别软件辅助的情况下，[$EQ-Radio#ai_product*]通过测量呼吸和心跳的微小变化，利用无线信号捕捉到一些肉眼不一定能察觉的人类行为，判断一个人到底处于以下四种情绪中的哪一种：激动、开心、生气或者忧伤，正确率高达87%。[$美国#Gep*]麻省理工学院教授和该项目的负责人[@Dina Katabi#Person*]预测，这个系统会被运用于娱乐、消费者行为和健康护理等方面：电影工作室和广告公司也可以用这个系统来测试观众实时的反应；而在智能家居的环境中，该系统可以通过捕捉与人的心情有关的信息，调节室内温度，或者建议你应该呼吸一些新鲜空气。 现有的情绪监控方法大多依赖于视听设备或者是安装在人身上的感应器，这两种技术都有缺点：面部表情并不一定符合内心状态，而安装在身上的感应器（比如胸带和心电监护仪）会造成各种不便，而且一旦它们的位置稍微移动，监测到的数据就不精确了。 [$EQ-Radio#ai_product*]会发送能监测生理信息的无线信号，该信号最终会反馈给设备本身。其中的算法可以分析心跳之间的微小变化，从而判断人们的情绪。消极情绪会被判定为“忧伤”，而正面且高涨的情绪会被判定为“激动”。尽管这样的测量会因人而异，但其中还是有内在统一性。通过了解人们处于不同的情绪状态下，他们的心跳会如何变化，我们就可以对他所处的情绪状态进行有效的判断。 在他们设计的实验中，参与实验者选择他们记忆中最能代表激动、开心、生气、忧伤以及毫无情感的一段视频或音乐。在掌握了这段时长两分钟的视频里的五种情绪设置后，[$EQ-Radio#ai_product*]可以精确地通过一个人的行为判断他处于这四种情绪中的哪一种。与微软研发的基于视觉和面部表情的Emotion API相比，[$EQ-Radio#ai_product*]在识别喜悦、忧伤和愤怒这三个情绪上精确度更高。同时，这两种系统在判断中性情绪时的精准度差不多，因为毫无情绪的脸总是更容易被识别。 目前，对[$美国#Gep*]麻省理工学院计算机科学与[$人工智能#ai_tec*]实验室而言，最艰巨的任务就是摆脱不相关数据的干扰。比如，为了分析心率，他们要抑制呼吸可能带来的影响，因为呼吸时，人的肺部起伏比他心跳时的心脏起伏要大。  ../Library/Containers/com.tencent.xinWeChat/Data/Library/Application%20Support/com.tencent.xinWeChat/2.0b4.0.9/4b94897be7738b56cfe21cb08bcb6803/Message/MessageTemp/4b94897be7738b56cfe21cb08bcb6803/Image/411546382342_.pic.jpg../Library/Containers/com.tencent.xinWeChat/Data/Library/Application%20Support/com.tencent.xinWeChat/2.0b4.0.9/4b94897be7738b56cfe21cb08bcb6803/Message/MessageTemp/4b94897be7738b56cfe21cb08bcb6803/Image/421546382342_.pic.jpg图 9 [$EQ-Radio#ai_product*]无线信号监测 4.3 医疗康复 近年来，[$情感计算#ai_tec*]运用于自闭症治疗得到越来越多的关注。例如，[$美国#Gep*]麻省理工学院[$情感计算#ai_tec*]团队正在开发世界上第一个可穿戴的[$情感计算#ai_tec*]技术设备：一个具有社交智能的假肢，用来实时检测自闭症儿童的情感，帮助机器人使用自闭症儿童独有的数据，来评估这些互动过程中每个孩子的参与度和兴趣。这个装置用一个小型照相机，分析孩子的面部表情和头部运动来推断他们的认知情感状态。还有一种叫“[@galvactivator#ai_product*]”的工具，通过测量穿戴者的皮肤电流数据，推断孩子的兴奋程度。这个像手套一样的设备可以利用发光二极管描绘出人体生理机能亢奋程度的图谱。这种可视化的展现方式，能够清晰地展示出人的认知情感水平。[@NAO机器人#ai_product*]和个性化的[$机器学习#ai_tec*]在治疗自闭症患者上也表现出很大的优越性： . [$NAO机器人#ai_product*] 人类治疗师会向孩子展示一张照片或者闪存卡片，用来表示不同的情绪，以教会他们如何识别恐惧、悲伤或喜悦的表情。治疗师随后对机器人进行编程，向孩子们展示这些相同的情绪，并且在孩子与机器人交往时观察孩子。孩子们的行为提供了宝贵的反馈信息，机器人和治疗师可以根据反馈信息继续学习。 研究人员在这项研究中使用了SoftBank Robotics NAO类人机器人。NAO将近2英尺高，类似于装甲超级英雄，通过改变眼睛的颜色、肢体的运动以及声音的音调来表达不同的情绪。参加这项研究的35名自闭症儿童中，有17人来自日本，18人来自塞尔维亚，年龄从3岁到13岁不等。他们在35分钟的会议中以各种方式对机器人做出反应，从看起来无聊和困倦，到在房间里兴奋地跳来跳去，拍手，大笑或触摸机器人。研究中的大多数孩子对机器人的看法是，它不仅仅是一个玩具，应该尊重NAO，因为它是一个真实的人。另外，人类用许多不同的方式改变自己的表情，但机器人则通过同样的方式来改变表情，这对孩子来说更加有利，因为孩子可以通过非常有条理的方式学习如何表达表情[16] 。  图 10 [$NAO机器人#ai_product*] . 个性化的[$机器学习#ai_tec*] 麻省理工学院的研究小组意识到，具有[$深度学习#ai_tec*]能力的治疗机器人能够更好感知儿童的行为的。[$深度学习#ai_tec*]系统使用分层的多层数据处理来处理其任务，每一个连续的层都是对原始数据抽象的表示。 尽管自20世纪80年代以来[$深度学习#ai_tec*]的概念已经出现，但直到最近才有足够的计算能力来实现这种[$人工智能#ai_tec*]。[$深度学习#ai_tec*]已被用于自动语音和对象识别程序中，这种应用非常适合解决面部、身体和声音等多重特征的问题，从而更好地理解抽象的概念，如儿童的参与感。 对于治疗机器人，研究者构建了一个个性化框架，可以从收集的每个孩子的数据中学习。研究人员拍摄了每个孩子的脸部表情、头部和身体动作、姿势和手势，记录了儿童手腕上显示器的心率、体温和皮肤汗液反应作为数据。这些机器人的个性化[$深度学习#ai_tec*]网络是根据这些视频、音频和生理数据的层次，针对孩子的自闭症诊断和能力、文化和性别的信息构建的。研究人员将机器人对儿童行为的估计与五位人类专家的估计数字进行了比较，这些专家连续对孩子的录像和录音进行编码，以确定孩子在会议期间高兴或不安程度，是否感兴趣以及孩子的表现。比较发现，机器人对儿童行为的估计要比专家更加具体清晰。 4.4 舆情监控 网络调查法、统计规则法和文本内容挖掘是三种经常被使用的网络舆情分析方法。大数据时代的来临使传统的舆情分析方式发生改变，大数据时代数据量突增、数据产生的速度极快、冗余信息占比高的特性不仅给舆情分析带来新的发展机遇，也带来了新的难度和挑战。基于简单调查和统计的舆情分析方法将无法适用于大数据环境下的网络社区文本。当前国内外对舆情分析技术的研究也大多以大数据环境为背景，与传统舆情分析技术相比，大数据时代网络社区的舆情分析技术更多地集中于对数据的获取，并采取文本数据分析、数据挖掘、语义分析等技术获取舆情信息。当前国内外的舆情分析技术研究主要集中于[@话题识别#ai_tec*]与[@话题跟踪#ai_tec*]、[@意见领袖识别#ai_tec*]以及[@情感倾向判别#ai_tec*]这三个方面。 [$话题识别#ai_tec*]与[$话题跟踪#ai_tec*]首先在文本中识别出新话题，接下来在一段时间内检测并实时跟踪话题，实现该话题的再现，研究其随时间发展的演化过程。聚类方法常用于进行[$话题识别#ai_tec*]。在国外研究中，话题检测与跟踪（TDT）是了解社交媒体热点话题及其演变过程的重要手段。 意见领袖的发现和识别重点在于评价指标的制定以及模型的构建。例如，曹玖新等将网络社区用户看作一个个节点，根据节点之间信息的交互和传播过滤，从用户结构、行为和情感三个特征维度挖掘意见领袖。 情感倾向判别在舆情研究中最为常见，首先收集web金融领域的文本数据属性，接下来构建金融领域的情感词典，最后结合语义分析，将语义规则应用到情感及情感强度识别当中，提升了分类器的准确率M。[@王永#Person*]等人将倾向分析应用到客户评论信息挖掘当中，结合情感词之间的依存关系计算面向产品特征的情感倾向得分，从网络评论中获取有价值的商业信息。国外针对Twitter的情感倾向分析研究居多，用以获取有价值的信息和舆论导向，例如，结合语言规则特征可以分别获取正面和负面的Twitter文章，反应公众的舆情态度[17] 。   内页背景6g.jpg5 趋势篇 5.1 论文研究发展趋势 Trend analysis（http://trend.aminer.cn）基于AMiner的2亿篇论文数据进行深入挖掘，包括对技术来源、热度、发展趋势进行研究，进而预测未来的技术前景。技术趋势分析描述了技术的出现、变迁和消亡的全过程，可以帮助研究人员理解领域的研究历史和现状，快速识别研究的前沿热点问题。 下图是当前[$情感计算#ai_tec*]领域的热点技术趋势分析，通过Trend analysis分析挖掘可以发现当前该领域的热点研究话题Top10是Affective Computing、Social Robot、Emotion Recognition、Human Computer Interaction、Feature Extraction、Support Vector Machine、Facial Expression、Human Robot Interaction、Behavioural Sciences Computing、Face Recognition。  图 11 [$情感计算#ai_tec*]发展趋势 根据Trend analysis的分析我们可以发现，该领域当前最热门的话题是Affective Computing，从全局热度来看，Affective Computing的话题热度虽然有所起伏，但从20世纪90年代开始，热度迅速上升，甚至在五年内超过了此前的话题Top 1 Emotion Recognition，并且至今其话题热度始终保持在Top1，论文的发表数量也较多；Social Robot的研究热度跟随Affective Computing同期上升，近几年话题热度更是超越Emotion Recognition成为Top2话题；另外，前期比较热门的Feature Extraction经过了一段时间的低迷期后，也回到了Top3的位置。  图 12 [$情感计算#ai_tec*]2007年经典论文 通过拖动趋势分析页面的时间轴，我们可以在上图左框中看到2007年同期的经典论文，引用量前五的论文分别如下： 1. 论文标题：Numerical Recipes 3rd Edition: The Art of Scientific Computing 论文作者：William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery 引用量：123789 2. 论文标题：Interaction Design: Beyond Human Computer Interaction 论文作者：Helen Sharp, Yvonne Rogers, Jenny Preece 引用量：7007 3. 论文标题：Dynamic texture recognition using local binary patterns with an application to facial expressions 论文作者：Guoying Zhao, Matti Pietikainen 引用量：1878 4. 论文标题：Socially intelligent robots: dimensions of human-robot interaction 论文作者：Kerstin Dautenhahn 引用量：616 5. 论文标题：Ensemble methods for spoken emotion recognition in call-centres 论文作者：Donn Morrison, Ruili Wang, Liyanage C. De Silva 引用量：285  C:\Users\Dai\Desktop\1554177426(1).jpg图 13 1970-2019论文研究方向趋势图 AMiner通过对1970年至2019年发表的[$情感计算#ai_tec*]相关论文进行数据分析，绘制出论文研究方向的发展趋势图。数据分析的论文主要来自于[$情感计算#ai_tec*]领域的顶级学术会议，如ACMMM、KDD的相关workshop。从图像中可以看出，随着时代发展及研究的深入，control system方向的论文数量在逐渐减少，speech recognition、hidden markov model、signal process、feature extract等方面的研究成果不断增加。具体的论文关键词请见下表： 表 13 1970-2019各阶段前十位研究关键词 1970-1979年   5.2 [$情感计算#ai_tec*]技术预见 研究者根据[$情感计算#ai_tec*]领域近十年的相关论文，利用大数据分析、[$机器学习#ai_tec*]、[$人工智能#ai_tec*]等技术手段，建立算法模型及研发demo系统，分析挖掘出该领域的技术发展热点。 技术预见图中点的大小表示该技术的热点（主要由相关论文数量的多少决定，相关论文越多，热度越高，点越大），各技术之间的连线表示2个技术关键词同时在N篇论文中出现过（当前N的取值为5）。  图 14 [$情感计算#ai_tec*]技术预见图 根据[$情感计算#ai_tec*]技术预见图（图 14），可以得出[$情感计算#ai_tec*]领域相关度最高的技术有3项，分别为：feature extraction、human computer interaction和emotion recognition。 按照技术前沿度，可以列出相关的主要技术关键词，以及该技术历年的变化趋势（论文发表数量变化趋势），及重要代表性成果。具体如下图所示：  图 15 [$情感计算#ai_tec*]预测热词图 从图 15中我们可以看出，[$情感计算#ai_tec*]领域预测前沿度比较高的前四热词有：autism spectrum disorder（前沿度为1428）、support vector machine（前沿度为1096）、deep learning（前沿度为1058）和semantic web（前沿度为1031）。 5.3 [$情感计算#ai_tec*]未来发展 . 数据库的建立 现在已实现的[$情感计算#ai_tec*]大部分原型情感的识别来源单一。数据库本身存在短板，如训练分类的样本数少，体态识别大多依赖于一组有限的肢体表达（跳舞、手势、步态等），只关注内部效度而缺少外部效度。因此识别方面，未来研究应在情感分类方面继续努力，创建新的数据库，尤其是婴幼儿及儿童数据库的建立。 . 神经科学与[$情感计算#ai_tec*]的结合 神经科学方面，人类大脑情感过程的神经解剖学基础极其复杂并且远未被理解，因此该领域还不能为开发[$情感计算#ai_tec*]模型提供充足的理论基础。 . 情感的测试 