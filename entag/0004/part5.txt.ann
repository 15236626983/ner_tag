As discussed in the 2016 [@Federal Big Data Research and Development Strategic Plan#ai_program*], 34 many fundamental new tools and technologies are needed to achieve intelligent [@data understanding#ai_product*] and [@knowledge discovery#ai_product*]. Further progress is needed in the development of more advanced machine learning algorithms that can identify all the useful information hidden in big data. Many open research questions revolve around the creation and use of data, including its veracity and appropriateness for [@AI system#ai_product*] training. The veracity of data is particularly challenging when dealing with vast amounts of data, making it difficult for humans to assess and extract knowledge from it. While much research has dealt with veracity through data quality assurance methods to perform data cleaning and [$knowledge discovery#ai_product*], further study is needed to improve the efficiency of data cleaning techniques, to create methods for discovering inconsistencies and anomalies in the data, and to develop approaches for incorporating human feedback. Researchers need to explore new methods to enable data and associated metadata to be mined simultaneously. Many[@ AI applications#ai_product*] are interdisciplinary in nature and make use of heterogeneous data. Further investigation of multimodality [@machine learning#ai_product*] is needed to enable [$knowledge discovery#ai_product*] from a wide variety of different types of data (e.g., discrete, continuous, text, spatial, temporal, spatio-temporal, graphs). [@AI#ai_product*] investigators must determine the amount of data needed for training and to properly address large-scale versus long-tail data needs. They must also determine how to identify and process rare events beyond purely statistical approaches; to work with knowledge sources (i.e., any type of information that explains the world, such as knowledge of the law of gravity or of social norms) as well as data sources, integrating models and ontologies in the learning process; and to obtain effective learning performance with little data when big data sources may not be available.