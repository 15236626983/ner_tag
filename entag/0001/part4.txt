All U.S. military services are working to incorporate AI into semiautonomous and autonomous vehicles, including fighter aircraft, drones, ground vehicles, and naval vessels. AI applications in this field are similar to those for commercial semiautonomous vehicles, which use AI technologies to perceive the environment, recognize obstacles, fuse sensor data, plan navigation, and even communicate with other vehicles. The Air Force Research Lab completed phase-two tests of its Loyal Wingman program, which pairs an older-generation, uninhabited fighter jet (in this case, an F-16) with an inhabited F-35 or F-22. During this event, the uninhabited F-16 test platform autonomously reacted to events that were not preprogrammed, such as weather and unforeseen obstacles. 79 As the program progresses, AI may enable the “loyal wingman” to accomplish tasks for its inhabited flight lead, such as jamming electronic threats or carrying extra weapons. The Army and the Marine Corps tested prototypes of similar vehicles that follow soldiers or vehicles around the battlefield to accomplish independent tasks. For example, the Marine Corps’ Multi-Utility Tactical Transport (MUTT) is a remote-controlled, ATV-sized vehicle capable of carrying hundreds of pounds of extra equipment. Although the system is not autonomous in its current configuration, the Marine Corps intends for follow-on systems to have greater independence. Likewise, the Army plans to field a number of Robotic Combat Vehicles (RCVs) with different types of autonomous functionality, including navigation, surveillance, and IED removal. These systems will be deployed as “wingmen” for the optionally inhabited Next Generation Ground Vehicle, tentatively scheduled for initial soldier evaluations in FY2020. DARPA completed testing of the Anti-Submarine Warfare Continuous Trail Unmanned Vessel prototype, or “Sea Hunter,” in early 2018 before transitioning program development to the Office of Naval Research. If Sea Hunter enters into service, it would provide the Navy with the ability to autonomously navigate the open seas, swap out modular payloads, and coordinate missions with other unmanned vessels—all while providing continuous submarine-hunting coverage for months at a time. Some analysts estimate that Sea Hunter would cost around $20,000 a day to operate, in contrast to around $700,000 for a traditionally inhabited destroyer. DOD is testing other AI-fueled capabilities to enable cooperative behavior, or swarming. Swarming is a unique subset of autonomous vehicle development, with concepts ranging from large formations of low-cost vehicles designed to overwhelm defensive systems to small squadrons of vehicles that collaborate to provide electronic attack, fire support, and localized navigation and communication nets for ground-troop formations. A number of different swarm capabilities are currently under development. For example, in November 2016, the Navy completed a test of an AI-enabled swarm of five unmanned boats that cooperatively patrolled a 4-by-4-mile section of the Chesapeake Bay and intercepted an “intruder” vessel. The results of this experiment may lead to AI technology adapted for defending harbors, hunting submarines, or scouting in front of a formation of larger ships. The Navy also plans to test swarms of underwater drones, and the Strategic Capabilities Office has successfully tested a swarm of 103 air-dropped micro-drones. Lethal Autonomous Weapon Systems (LAWS) are a special class of weapon systems that use sensor suites and computer algorithms to independently identify a target and employ an onboard weapon system to engage and destroy the target without manual human control of the system. Although these systems generally do not yet exist, it is believed they would enable military operations in communications-degraded or -denied environments in which traditional systems may not be able to operate. The U.S. military does not currently have LAWS in its inventory, although there are no legal prohibitions on the development of LAWS. DOD Directive 3000.09, “Autonomy in Weapon Systems,” outlines department policies for semiautonomous and autonomous weapon systems. The directive requires that all systems, regardless of classification, be designed to “allow commanders and operators to exercise appropriate levels of human judgment over the use of force” and to successfully complete the department’s weapons review process. Any changes to the system’s operating state require that the system go through the weapons review process again to ensure that it has retained the ability to operate as intended. Autonomous weapons and a limited type of semiautonomous weapons must additionally be approved before both development and fielding by the Under Secretary of Defense for Policy, the Chairman of the Joint Chiefs of Staff, and either the Under Secretary of Defense for Acquisition and Sustainment or the Under Secretary of Defense for Research and Engineering. Human-supervised autonomous weapons used for point defense of manned installations or platforms—but that do not target humans—and autonomous weapons that “apply non-lethal, non-kinetic force, such as some forms of electronic attack, against materiel targets” are exempted from this senior-level review. Despite this policy, some senior military and defense leaders have expressed concerns about the prospect of fielding LAWS. For example, in 2017 testimony before the Senate Armed Services Committee, then-Vice Chairman of the Joint Chiefs of Staff General Paul Selva stated, “I do not think it is reasonable for us to put robots in charge of whether or not we take a human life.” Regardless, General Selva explained that the military will be compelled to address the development of this class of technology in order to find its vulnerabilities, given the fact that potential U.S. adversaries are pursuing LAWS. Indeed, as Secretary of Defense Mark Esper has noted, “Chinese weapons manufacturers are selling drones advertised as capable of full autonomy, including the ability to conduct lethal targeted strikes.”