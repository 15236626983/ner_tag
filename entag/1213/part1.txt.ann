The [@military#Org*] has its eye on [@artificial intelligence#ai_tec*] solutions to everything from data analysis to surveillance, maintenance and medical care, but before the [@Defense Department#Org*] moves full steam ahead into an [@AI#ai_tec*] future, they're laying out some ethical principles to live by. Defense Secretary [@Mark Esper#Person*] signed off on five guidelines in a memo released Monday, "[@The United States#Gpe*], together with our allies and partners, must accelerate the adoption of [@AI#ai_tec*] and lead in its national security applications to maintain our strategic position, prevail on future battlefields, and safeguard the rules-based international order," said [@Esper#Person*] wrote. "[@AI#ai_tec*] technology will change much about the battlefield of the future, but nothing will change [@America#Gpe*]'s steadfast commitment to responsible and lawful behavior." The list is the result of a 15-month study by the [@Defense Innovation Board#Org*], which is made up of academics and executives in tech and business, who presented their proposed principles in a public forum at [@Georgetown University#Org*] in [@October#Date*]. According to [@Esper#Person*]'s Monday memo, the [@Pentagon#Org*] pledges that its [@AI#ai_tec*] efforts will be: 1) Responsible, 2) Equitable, 3) Traceable, 4) Reliable and 5) Governable. In short, any technology's development and operation should be carefully developed and used, have safeguards against bias in data analysis, be auditable to find the sources of mistakes and correct them, have narrowly-defined parameters for use and have back-up plans for shut down in case something goes wrong. "We owe it to the [@America#Gpe*]n people and our men and women in uniform to adopt [@AI#ai_tec*] principles that reflect our nation's values of a free and open society," Lt. Gen. [@Jack Shanahan#Person*], head of the [@Joint Artificial Intelligence Center#Org*], told reporters Monday. "This runs in stark contrast to [@Russia#Gpe*] and [@China#Gpe*], whose use of [@AI#ai_tec*] tech for military purposes raises serious concern about human rights, ethics and international norms." [@China#Gpe*], for example, has used its facial recognition [@AI#ai_tec*] technology to surveil its citizens' public activity. "I do not believe … that [@China#Gpe*] or [@Russia#Gpe*] are having any sort of conversation like we're having today," [@Shanahan#Person*] said, taking questions from the press in a public broadcast. [@The White House#Org*] is scheduled to release its own set of principles this summer, he said. "Our intentions are clear: We will do what it takes to ensure that the [@U.S. military#Org*] lives up to our nation's ethical values while maintaining and strengthening [@America#Gpe*]'s technological advantage," [@Shanahan#Person*] said. [@DoD#Org*] is at the "ground floor" of its [@AI#ai_tec*] journey, according to [@Shanahan#Person*], so there are few concrete examples of [@AI#ai_tec*] technology that will be subject to these principles. The [@JAIC#Org*], his organization, has been working developing a tool for [@UH-60 Black Hawk helicopter#MISC*] maintenance, he said, as well as some cyber defense technology and solutions to make military health care more efficient. One past project, dubbed [@Maven#ai_program*], made headlines in [@2018#Date*], when [@Gizmodo#Org*] reported that [@Google#Org*] had been quietly allowing [@DoD#Org*] access to a software program that could use [@AI#ai_tec*] to recognize objects in drone footage. Some [@Google#Org*] employees were dismayed to find that their employer was potentially helping the military home in on human targets. "We would be doing these [@AI#ai_tec*] ethics principles regardless of the angst in the tech industry," [@Shanahan#Person*] said. "And sometimes I think the angst is a little hyped, but we do have people who have serious concerns about working with the [@Department of Defense#Org*]." In hindsight, he said, secretly launching [@Project Maven#ai_program*] would not line up with the new ethics principles. "If we would have had the [@AI#ai_tec*] ethics principles three years ago … and our starting point with one of the big tech companies was that — and we were transparent about what we were trying to do and why we were trying to do it — maybe we would have had a different outcome," he said.