Although O
DNNs B-ai_tec
offer O
high O
performance O
in O
many O
applications, O
their O
sub-symbolic B-ai_tec
computations I-ai_tec
with O
perhaps O
millions O
of O
parameters O
makes O
it O
difficult O
to O
understand O
exactly O
how O
input O
features O
contribute O
to O
system O
recommendations. O
Since O
DNNs B-ai_tec
high O
performance O
is O
critical O
for O
many O
applications, O
there O
is O
a O
considerable O
interest O
in O
how O
to O
make O
them O
more O
interpretable O
(see O
[39] O
for O
a O
review). O
Many O
algorithms O
for O
interpreting O
DNNs B-ai_tec
transform O
the O
DNN-processing B-ai_tec
into O
the O
original O
input O
space O
in O
order O
to O
visualize O
discriminating O
features. O
Typically, O
two O
general O
approaches O
are O
used O
for O
feature O
visualization, O
activation B-ai_tec
maximation I-ai_tec
and O
DNN B-ai_tec
explanation I-ai_tec
. O
Activation B-ai_tec
maximation I-ai_tec
computes O
which O
inputs O
features O
that O
will O
maximally O
activate O
possible O
system O
recommendations. O
For O
image B-ai_product
classification I-ai_product
, O
this O
represents O
the O
ideal O
images O
that O
show O
discriminating O
and O
recognizable O
features O
for O
each O
class. O
However, O
the O
images O
often O
look O
unnatural O
since O
the O
classes O
may O
use O
many O
aspects O
of O
the O
same O
object O
and O
the O
semantic O
information O
in O
images O
is O
often O
spread O
out O
[43]. O
Some O
examples O
of O
methods O
for O
activation B-ai_tec
maximation I-ai_tec
are O
gradient B-ai_tec
ascent I-ai_tec
[13], O
better O
regularization O
to O
increase O
generalizability O
[54], O
and O
synthesizing O
preferred O
images O
[41, O
40]. O
DNN B-ai_tec
explanation I-ai_tec
explains O
system O
recommendations O
by O
highlighting O
discriminating O
input O
features. O
In O
image B-ai_product
classification I-ai_product
, O
such O
visualizations O
may O
highlight O
areas O
that O
provide O
evidence O
for O
or O
against O
a O
certain O
class O
[68] O
or O
only O
show O
regions O
that O
contain O
discriminating B-ai_tec
features I-ai_tec
[3]. O
One O
approach O
for O
calculating O
discriminating B-ai_tec
features I-ai_tec
is O
sensitivity O
analysis O
using O
local B-ai_tec
gradients I-ai_tec
or O
other O
measure O
of O
variation O
[39]. O
However, O
one O
problem O
with O
sensitivity O
analysis O
is O
that O
it O
may O
indicate O
discriminating B-ai_tec
features I-ai_tec
that O
are O
not O
present O
in O
the O
input. O
For O
example, O
in O
image B-ai_product
classification I-ai_product
the O
sensitivity O
analysis O
may O
indicate O
obscured O
parts O
of O
an O
object O
rather O
than O
the O
visible O
parts O
[51]. O
Layer-wise O
relevance O
propagation O
avoids O
this O
problem O
by O
considering O
both O
feature O
presence O
and O
model O
reaction O
[4]. O

