In contrast to classification, AI-planning is based on models of domain dynamics. Fox et al. [15] describe how explanations for planning may use domain models to explain why actions were performed or not, why some action cannot be performed, causal relationships that enable future actions, and the need for replanning. Since fairness is important for many AI-applications, Tan et al. [59] describe how model distillation can be used to detect bias in black-box models. Model distillation simplifies larger more complex models without significant loss of accuracy. For transparency, they use generalized additive models based on shallow trees that model each parameter and the interaction between two parameters. They train a transparent model on system recommendations from the black-box model and one transparent model on the actual outcome. Hypothesis testing of differences in recommendations from the two models shows cases where the black-box model introduce a bias, which may then be diagnosed by comparing the two transparent models. The system was evaluated on recidivism risk, lending loan risk, and individual risk for being involved in a shooting incident. The results show that one black-box model underestimates recidivism risk for young criminals and Caucasians, while overestimating the risk for Native and African Americans.