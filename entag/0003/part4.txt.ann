[@Bayesian rule lists#ai_tec*] ([@BRL#ai_tec*]) is one example of interpretable models. [$BRL#ai_tec*] consist of series of if (condition) then (consequent) else (alternative) statements. Letham et al. [33] describes how [$BRL#ai_tec*] can be generated for a highly accurate and interpretable model to estimate the risk of stroke. The conditions discretize a high-dimensional multivariate feature space that influence the risk of stroke and the consequent describes the predicted risk of stroke. The [$BRL#ai_tec*] has similar performance as other [@ML-methods#ai_tec*] for predicting the risk of stroke and is just as interpretable as other existing scoring systems that are less accurate. [@Lexicon-based classifiers#ai_tec*] is another example of interpretable models for text classification. [$Lexicon-based classifiers#ai_tec*] multiplies the frequency of terms with the probability for terms occurring in each class. The class with the highest score is chosen as the prediction. Clos et al. [11] models lexicons using a [@gated recurrent network#ai_tec*] that jointly learns both terms and modifiers, such as adverbs and conjunctions. The lexicons where trained on whether posts in forum are for or against death penalty and sentiments towards commercial productions. The lexicons perform better than other [$ML-methods#ai_tec*] and are at the same time interpretable.