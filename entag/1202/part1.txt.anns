After O
a O
while O
the O
buzzwords O
start O
to O
ring O
hollow. O
What's O
" O
artificial B-ai_tec
intelligence I-ai_tec
" O
in O
practical O
terms? O
An O
Orwellian O
nightmare O
that O
will O
control O
our O
every O
battlefield O
maneuver? O
Or O
a O
helpful O
tool O
to O
aid O
the O
war O
fighter? O
Let's O
bring O
it O
down O
to O
Earth, O
make O
it O
tangible. O
AI B-ai_tec
can, O
for O
instance, O
scan O
a O
live O
video O
feed O
faster O
and O
more O
accurately O
than O
any O
human O
and O
then O
warn O
commanders O
of O
imminent O
danger.At O
least O
that's O
the O
premise O
behind O
an O
ongoing O
project O
at O
the O
Air B-MISC
Force I-MISC
Research I-MISC
Laboratory I-MISC
at O
Wright-Patterson B-MISC
Air I-MISC
Force I-MISC
Base I-MISC
. O
"Video O
is O
captured O
with O
such O
velocity O
and O
volume O
[that] O
no O
individual O
or O
team O
of O
individuals O
can O
hope O
to O
analyze O
that O
data O
in O
a O
meaningful O
way," O
said O
Scott B-Person
Clouse I-Person
, O
senior O
research O
engineer O
at O
the O
Decision O
Science O
Branch. O
AI B-ai_tec
offers O
a O
faster, O
smarter O
alternative. O
While O
video O
intelligence O
can O
be O
an O
invaluable O
resource, O
it's O
also O
a O
massive O
manpower O
suck. O
"In O
some O
instances, O
we O
are O
up O
to O
teams O
of O
30 O
people O
looking O
at O
one O
video O
feed, O
just O
to O
make O
sure O
we O
don't O
miss O
anything," O
Clouse B-Person
said. O
"There O
is O
an O
immediate O
need O
to O
cut O
down O
the O
number O
of O
people O
on O
a O
single O
feed, O
maybe O
even O
to O
the O
point O
where O
we O
could O
have O
a O
single O
person O
looking O
at O
multiple O
feeds. O
It O
could O
dramatically O
reduce O
the O
workload O
on O
the O
force."In O
late B-Date
2017 I-Date
the O
AFRL B-MISC
research I-MISC
team I-MISC
hit O
a O
milestone O
in O
its O
work, O
winning O
the O
Large-Scale O
Movie O
Description O
Challenge O
at O
the O
2017 B-Date
International B-MISC
Conference I-MISC
on I-MISC
Computer I-MISC
Vision I-MISC
in O
Venice B-Gpe
, O
Italy B-Gpe
. O
In O
that O
competition, O
AI-driven B-ai_product
systems I-ai_product
were O
tasked O
with O
creating O
simple O
written O
descriptions O
of O
short O
clips O
taken O
from O
commercial O
film O
footage. O
The O
techniques O
used O
here O
could O
in O
principal O
serve O
as O
the O
basis O
for O
an O
AI-driven B-ai_tec
situational O
awareness O
tool. O
While O
the O
team O
kept O
its O
movie O
captions O
deliberately O
terse O
— O
"Someone O
looks O
up, O
someone O
reads O
a O
letter" O
— O
video O
interpretation O
on O
the O
battlefield O
could O
perhaps O
offer O
an O
even O
deeper O
dive O
into O
video O
intelligence."On O
the O
battlefield O
you O
are O
not O
competing O
with O
the O
other O
audio, O
you O
are O
not O
competing O
with O
music O
in O
the O
background. O
You O
could O
deliver O
a O
more O
lengthy O
verbal O
description," O
said O
Vincent B-Person
Velten I-Person
, O
AFRL B-Org
's O
Multi-Domain B-Org
Sensing I-Org
Autonomy I-Org
Division I-Org
Decision I-Org
Science I-Org
Branch I-Org
technical O
advisor.For O
AI B-ai_tec
to O
interpret O
video O
data, O
the O
system O
must O
be O
told O
what O
to O
look O
for. O
Right O
now, O
programmers O
can O
set O
a O
simple O
system O
to O
identify O
specific O
shapes O
or O
colors O
or O
types O
of O
activity. O
Moving O
forward, O
they O
want O
the O
AI-driven B-ai_product
system I-ai_product
to O
cull O
more O
detailed O
information. O
In O
technical O
terms, O
the O
mechanism O
that O
enables O
this O
is O
called O
a O
recurrent B-ai_tec
neural I-ai_tec
net I-ai_tec
, O
or O
RNN B-ai_tec
. O

