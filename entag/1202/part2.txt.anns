The O
RNN B-ai_tec
adds O
the O
memory O
component O
to O
the O
process. O
"This O
is O
what O
gives O
you O
time, O
and O
time O
is O
what O
gives O
you O
context," O
Clouse B-Person
said. O
"You O
see O
a O
person O
standing O
next O
to O
the O
truck O
and O
then O
you O
see O
a O
person O
sitting O
in O
the O
truck. O
You O
can O
intuit O
that O
person O
got O
into O
the O
truck. O
You O
start O
to O
see O
relationships O
in O
the O
sequences."There's O
some O
urgency O
to O
this O
work, O
as O
the O
military O
comes O
to O
rely O
ever O
more O
heavily O
on O
video B-ai_tec
capture I-ai_tec
as O
a O
situational B-ai_product
awareness I-ai_product
tool I-ai_product
. O
Velten B-Person
pointed O
especially O
to O
the O
Air B-MISC
Force I-MISC
's O
use O
of O
video O
feeds O
from O
remotely O
piloted O
aircraft."The O
Air B-MISC
Force I-MISC
makes O
a O
lot O
of O
use O
of O
this O
stuff, O
and O
then O
there O
are O
also O
the O
small O
UAV B-ai_product
s O
that O
are O
becoming O
more O
and O
more O
interesting. O
That O
is O
right O
now O
the O
principle O
motivation," O
he O
said. O
The O
AFRL B-Org
team I-Org
needs O
about O
five O
more O
years O
to O
produce O
a O
battlefield-worthy O
version O
of O
its O
video O
scanning O
AI B-ai_tec
tool. O
To O
get O
to O
the O
finish O
line, O
researchers O
need O
to O
spend O
more O
time O
looking O
at O
actual O
intel O
and O
tackling O
specific O
military O
objectives. O
Just O
as O
last O
year's O
movie O
competition O
had O
a O
specific O
tactical O
goal O
— O
caption O
five O
seconds O
of O
a O
movie O
— O
the O
researchers O
need O
to O
build O
their O
tools O
around O
specific O
ISR O
objectives. O
The O
AI B-ai_tec
is O
only O
as O
good O
at O
what O
you O
tell O
it O
to O
do, O
and O
they're O
still O
refining O
the O
process O
of O
writing O
those O
instructions O
for O
the O
machines O
to O
follow. O
"We O
have O
a O
lot O
of O
data O
right O
now. O
What O
we O
need O
are O
concrete O
objectives O
to O
train O
the O
system," O
Clouse B-Person
said. O
"We O
need O
an O
operational O
setting O
where O
we O
have O
some O
data O
that O
is O
labeled O
or O
captioned O
appropriately O
that O
we O
can O
feed O
into O
the O
training O
mechanism, O
in O
order O
to O
train O
the O
systems O
on O
what O
to O
look O
for. O
"If O
it O
works, O
an O
AI-driven B-ai_product
system I-ai_product
could O
make O
it O
easier O
to O
pull O
the O
most O
important O
information O
from O
a O
video O
feed. O
Watching O
video O
takes O
time, O
far O
more O
time O
than O
it O
would O
take O
to O
read O
a O
simple O
sentence O
or O
two O
the O
sums O
up O
the O
relevant O
action. O
"We O
want O
to O
efficiently O
translate O
all O
this O
video O
information O
into O
a O
semantic O
form O
that O
is O
efficient O
for O
people O
to O
use," O
Clouse B-Person
said. O
"Fundamentally O
it O
means O
that O
you O
know O
what O
is O
going O
on O
and O
you O
know O
what O
has O
changed, O
without O
having O
to O
stare O
at O
every O
frame O
as O
it O
goes O
by." O

